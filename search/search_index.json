{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#general-information","title":"General Information","text":"<p>EXTPAR (External Parameters for Numerical Weather Prediction and Climate Application) is an official software of the COSMO Consortium .  It is used to prepare the external parameter data files that are used as input for the COSMO and the ICON model.</p> <p>The code is written in Fortran 90 and in Python. The Python scripts use CDO  (Climate Data Operators)  for the most compute-intensive parts. The code is also accelerated in some places with OpenMP parallelization.</p> <p>Once compiled, the code generates 6 Fortran executables and 9 Python scripts, which can be run simultaneously except for the final extpar_consistency_check.exe, which is used to tie together all the external parameter results into one output file.</p> <p>Information about the latest changes can be found in the Release Notes on GitHub .</p> <p>The technical and scientific documentation can be found in the User and Implementation Guide.</p>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#container","title":"Container","text":"<p>The easiest way to use EXTPAR is through the container provided with Dockerfile .  A ready-to-use image can be downloaded from C2SM docker hub   or even simpler via CLI:</p> <pre><code>docker pull c2sm/extpar:tagname\n</code></pre> <p>Alternatively, an image is provided as an asset of each release </p>"},{"location":"#wrapextpar","title":"WrapExtpar","text":"<p>The image provides a wrapper that only requires to set basic options, all other details are handled by the wrapper.</p> <p>The wrapper needs two different kinds of input:</p> <p>1. EXTPAR settings as JSON, see official docs</p> <pre><code>{\n  \"extpar\": {\n    \"igrid_type\": 1,\n    \"iaot_type\": 1,\n    \"ilu_type\": 1,\n    \"ialb_type\": 1,\n    \"isoil_type\": 1,\n    \"itopo_type\": 1,\n    \"lsgls\": false,\n    \"lfilter_oro\": false,\n    \"lurban\": false\n  }\n}\n</code></pre> <p>2. Execution options</p> <pre><code>  --input-grid INPUT_GRID\n                        COSMO: Fortran Namelist \"INPUT_COSMO_GRID\", ICON: Icon\n                        grid file\n  --raw-data-path RAW_DATA_PATH\n                        Path to folder \"linked_data\" of exptar-input-data\n                        repository\n  --run-dir RUN_DIR     Folder for running EXTPAR\n  --account ACCOUNT     Account for slurm job\n  --host HOST           Host\n  --no-batch-job        Run jobscript not as batch job\n</code></pre> <p>An example call could look like</p> <pre><code>docker run -v /c2sm-data/extpar-input-data:/data \\\n           -v /icon-grids:/grid \\\n           -v /my_local_dir:/work \\\n           extpar \\ \n           python3 -m extpar.WrapExtpar \\\n           --run-dir /work \\\n           --raw-data-path /data/linked_data \\\n           --account none \\\n           --no-batch-job \\\n           --host docker \\\n           --input-grid /grid/icon_grid.nc \\\n           --extpar-config /work/config.json\n</code></pre> <p>Below is a more detailed explanation about the mounted volumes:</p> <ul> <li><code>-v /c2sm-data/extpar-input-data:/data</code>: Mounts the input data at <code>/data</code> inside the container. This should be aligned with the <code>--raw-data-path</code> argument.</li> <li><code>-v /icon-grids:/grid</code>: Mounts a local folder with icon grids under <code>/grid</code> inside the container. This should be aligned with the <code>--input-grid</code> argument.</li> <li><code>-v /my_local_dir:/work</code>: Mounts a local folder for EXTPAR output at <code>/work</code> inside the container. This should be aligned with the <code>--run-dir</code> argument.</li> </ul>"},{"location":"#individual-executables","title":"Individual Executables","text":"<p>For those who require a more custom setup of EXTPAR or need settings that are not possible to specify through the wrapper, you can run each executable within the image too. For example:</p> <pre><code>docker run extpar bash -c \"extpar_topo_to_buffer\"\n</code></pre>"},{"location":"#bare-metal-build-on-levante","title":"Bare Metal Build on Levante","text":"<p>The installation steps are</p> <pre><code>git clone --recursive git@github.com:C2SM/extpar.git\ncd extpar\ngit submodule update\n./configure.levante.gcc\nsource modules.env\nmake -j 4\n</code></pre> <p>Furthermore copy all the <code>.exe</code> and <code>.py</code> files from <code>bin</code> to the directory  in which the namelist and all required input-data is present.</p> <p>You do then have two choices to run EXTPAR:</p> <ol> <li>configure the <code>PYTHONPATH</code> variable such that it includes to the <code>python/lib</code>    folder of the source repository</li> <li>build and install a python package for your user account</li> </ol>"},{"location":"#installing-extpar","title":"Installing EXTPAR","text":"<p>After you prepared EXTPAR (see above), you have two options to install and run the software.</p>"},{"location":"#option-1-pythonpath","title":"Option 1: PYTHONPATH","text":"<p>If you like to run the EXTPAR scripts without installing a package, make sure to have the <code>python/lib</code> folder in your <code>PYTHONPATH</code> variable. You can do this via</p> <pre><code>export PYTHONPATH=$PYTHONPATH:$(pwd)/python/lib\n</code></pre> <p>Afterwards you can <code>cd</code> into the <code>bin/</code> directory and run the corresponding executables, e.g.</p> <pre><code>cd bin\n./extpar_aot_to_buffer.exe\n</code></pre> <p>For more detailed compilation instructions see the Compile and Run section.</p>"},{"location":"#option-2-build-and-install-a-python-package","title":"Option 2: Build and install a python package","text":"<p>Alternatively you can build a python package and install it to your libraries. This has the advantages that the executables can be ran from anywhere in the system without the need to copy the executables themselves.</p> <p>To build the package, now run</p> <pre><code>python setup.py sdist\n</code></pre> <p>You can then install it via</p> <pre><code>pip install dist/extpar-*.tar.gz\n</code></pre> <p>Note</p> <p>If you do not have the permissions to install it into the system-wide python library, it will be installed for your user account only (you can also add the <code>--user</code> flag to <code>pip</code> to force this behaviour).</p> <p>If you did not install <code>extpar</code> into the system libraries, make sure that the <code>bin</code> folder of your local user is on your <code>PATH</code> variable to be able to run the EXTPAR scripts. This is usually done via</p> <pre><code>export PATH=\"$HOME/.local/bin:$PATH\"\n</code></pre> <p>You can then call the functionalities of <code>WrapExtpar.py</code> via</p> <pre><code>python -m extpar.WrapExtpar\n</code></pre> <p>or import the script in Python via</p> <pre><code>from extpar.WrapExtpar import generate_external_parameters\n</code></pre> <p>Or you call the executable scripts in your run directory, e.g.</p> <pre><code>extpar_aot_to_buffer.exe\n</code></pre>"},{"location":"#input-data","title":"Input Data","text":""},{"location":"#data-location","title":"Data Location","text":"<p>In order to run EXTPAR, input data files for the external parameter variables are needed. The data is provided on all supported machines:</p> Levante (DKRZ)co2 (ETHZ) <pre><code>/work/pd1167/extpar-input-data/linked_data\n</code></pre> <pre><code>/c2sm-data/extpar-input-data\n</code></pre> <p>The input data files are also stored in a git-LFS data repository found at: https://gitlab.dkrz.de/extpar-data/extpar-input-data . Instructions to download or update the input data files can be found in this repository. To gain access to the git-LFS input data repository, contact the EXTPAR source code administrator.</p>"},{"location":"#testing","title":"Testing","text":"<p>The EXTPAR code comes with a technical testsuite to ensure the accuracy of the results. Weekly tests run for compilers:</p> <ul> <li>GCC</li> </ul> <p>For more information about how the testsuite can be run or new test added see the Testing section.</p>"},{"location":"#information-for-developers","title":"Information for Developers","text":"<p>In case you want to contribute to EXTPAR please have a look at our coding rules and development workflow.</p>"},{"location":"#support","title":"Support","text":"<p>In the case of issues or questions, please create an issue on GitHub .</p>"},{"location":"SUMMARY/","title":"SUMMARY","text":"<ul> <li>Home</li> <li>Compile and Run</li> <li>Dependencies</li> <li>Testing</li> <li>Development</li> <li>Release Notes</li> <li>User Guide</li> </ul>"},{"location":"compile_run/","title":"Compile and Run","text":""},{"location":"compile_run/#compilation","title":"Compilation","text":"<p>Since Version 5.4, EXTPAR is built with an autotools based build-system. This has been necessary to accomodate for the additional C source code files and newly required libraries.</p> <p>There are three options to compile Extpar: </p>"},{"location":"compile_run/#in-source-build","title":"In-source build","text":"<pre><code>./configure.&lt;hostname&gt;.&lt;compiler&gt;\nsource modules.env  \nmake   \n</code></pre>"},{"location":"compile_run/#out-of-source-build","title":"Out-of-source build","text":"<pre><code>mkdir build-&lt;my_self_defined_note&gt;\ncd build-&lt;my_self_defined_note&gt;\npath/to/extpar/installation/configure.&lt;hostname&gt;.&lt;compiler&gt;\nsource modules.env  \nmake  \n</code></pre>"},{"location":"compile_run/#install-binaries-only-in-external-directory","title":"Install binaries only in external directory","text":"<pre><code>./configure.&lt;hostname&gt;.&lt;compiler&gt; --prefix=&lt;my_external_directory&gt;\nsource modules.env  \nmake install  \n</code></pre> <p>The binaries will be installed in <code>my_external_directory/bin</code>.</p>"},{"location":"compile_run/#restart-build-from-scratch","title":"Restart build from scratch","text":"<pre><code>make distclean \n</code></pre>"},{"location":"compile_run/#configure-for-new-machines","title":"Configure for new machines","text":"<p>The first step in creating a new machine setup is to take one of the existing configure wrapper scripts and adapt it to your local environment. The scripts are called <code>configure.&lt;hostname&gt;.&lt;compiler&gt;</code>.</p>"},{"location":"compile_run/#running","title":"Running","text":"<p>The Fortran executables </p> <ul> <li>extpar_aot_to_buffer.exe</li> <li>extpar_landuse_to_buffer.exe</li> <li>exptar_soil_to_buffer.exe</li> <li>extpar_topo_to_buffer.exe</li> <li>extpar_flake_to_buffer.exe </li> <li>extpar_consistency_check.exe </li> </ul> <p>can simply be copied to the <code>run/</code> directory.</p> <p>The main python scripts </p> <ul> <li>extpar_alb_to_buffer.py</li> <li>extpar_cru_to_buffer.py</li> <li>extpar_ndvi_to_buffer.py</li> <li>extpar_emiss_to_buffer.py</li> <li>exptar_era_to_buffer.py</li> <li>extpar_ahf_to_buffer.py</li> <li>extpar_isa_to_buffer.py </li> <li>extpar_cdnc_to_buffer.py</li> <li>extpar_edgar_to_buffer.py </li> </ul> <p>can be treated like the Fortran binaries and copied to the <code>run/</code> directory. Make sure the namelist.py is also present in the <code>run/</code> directory.  </p> <p>All self-written Python modules are stored in <code>python/lib</code>  and do not need to be copied to the respective run directory, but the environment variable <code>PYTHONPATH</code> needs to be set to the following:  </p> <pre><code>export PYTHONPATH=$PYTHONPATH:&lt;absolute_path_to_python&gt;/lib\n</code></pre> <p>Some runscript examples are available under <code>run_scripts</code> . Just adapt them to your needs!</p>"},{"location":"dependencies/","title":"Dependencies","text":"<p>EXTPAR contains Fortran Code as well as hybrid Python-CDO scripts. Both code bases need external libraries and installations.</p>"},{"location":"dependencies/#libraries","title":"Libraries","text":""},{"location":"dependencies/#fortran","title":"Fortran","text":"<p>EXTPAR needs the following libraries for the Fortran-Code:</p> <ul> <li>NetCDF</li> <li>JASPER</li> <li>PNG</li> <li>Z LIB</li> </ul>"},{"location":"dependencies/#python-cdo","title":"Python-CDO","text":"<p>EXTPAR needs the following Python packages and installations:</p> <ul> <li>at least Python 3.6</li> <li>module netCDF4</li> </ul> <p>The module netCDF is the Python interface to the netCDF C library. It allows the user create and manipulate netCDF files with Python. For more detailed information please visit netCDF Python .</p> <p>Additionally, an installation of CDO (Climate Data Operators) is required. All necessary information about this tool can be found at CDO-MPI.</p> <p>Be sure that these libraries are installed on your system or install them yourself by following the installation instructions provided with the libraries.</p>"},{"location":"dependencies/#on-the-dkrz-machine-levante","title":"On the DKRZ machine Levante","text":"<p>All the required libraries are already installed on the DKRZ machine.</p>"},{"location":"development/","title":"Information for EXTPAR Developers","text":""},{"location":"development/#git-and-github","title":"Git and Github","text":"<p>The EXTPAR code is developed using the Git version control system and the Github web interface .  Outstanding bugs and requested features are tracked using the Issues  section of the Github repository.  Additionally, automated testing of newly developed features is integrated into the Github interface using the Jenkins CI tool.  </p>"},{"location":"development/#main-branches","title":"Main branches","text":"<p>The master branch is protected and only the core development team is allowed to modify the master branch. All tags and releases are based on this branch.</p>"},{"location":"development/#supporting-branches","title":"Supporting branches","text":"<p>Any new code development should be done in a topic branch. Topic branches are merged back into master by opening a pull request. Code must be peer reviewed by the source code administrator.</p> <p>Supporting branches are removed once successfully merged in the master branch.</p>"},{"location":"development/#developments-with-new-input-data-sets","title":"Developments with new input data sets","text":"<p>Any new EXTPAR code that is accompanied by a new input data file or files should be added with a simultaneous pull request in both this code repository (for the code changes) and in the extpar-input-data repository  (for the addition of the input data files). The topic branch for both pull requests should have the same name, in order to enable the synchronization of the code and input-data repositories.</p>"},{"location":"development/#testing-new-developments","title":"Testing new developments","text":"<p>Once a developer has finished developing a new feature or bug fix, they should make a  pull request on the Github repository from their topic branch into the master-branch. Then, they should write the following comment into the pull request conversation: </p> <pre><code>launch jenkins\n</code></pre> <p>This will start the automated testing, and the code will be compiled and tested on co2 (ETH) and Levante (DKRZ).</p> <p>If the tests fail, then the developer should fix the issues and resubmit the testing on Jenkins. Once all of the tests are passing, then they should notify the source code administrator that the pull request is ready for review and merging into the master-branch.  </p>"},{"location":"development/#fortran-code","title":"Fortran Code","text":""},{"location":"development/#logging","title":"Logging","text":"<p>In case you want to add some additional prints in EXTPAR, please use the logger described below.</p> <p>CALL the built-in logger-functions in order to print messages or variables in the specific logfile of each EXTPAR executable. The logger has three different levels of messages to print:</p> <ol> <li> <p><code>logging%info(your_message)</code>: info-prints for better orientation during code execution, variables or other stuff.</p> </li> <li> <p><code>logging%warning(your_message)</code>: warnings, like wrong namelist-inputs, unsupported NetCDF versions or problems with some data points.</p> </li> <li> <p><code>logging%error(your_message, __FILE__,__LINE__)</code>: errors that occur during I/O, allocation, that requires an abort of EXTPAR. </p> </li> </ol> <p>As your_message needs to be a sequence of characters, use</p> <pre><code>WRITE(message_text,*)var_x, 'is now', var_y\n</code></pre> <p>and then </p> <pre><code>CALL logging%inf0(message_text) \n</code></pre> <p>to print the values of <code>var_x</code> and <code>var_y</code> to the logfile.</p> <p>For quick debugging-prints ONLY use</p> <pre><code>WRITE(logging%fileunit,*)var_x, 'is now', var_y \n</code></pre>"},{"location":"development/#coding-rules-and-best-practices","title":"Coding Rules and Best Practices","text":"<ol> <li> <p>All features available in Fortran 2008 as far as supported by Intel, GCC, and NAG are allowed.</p> </li> <li> <p>Use up to the allowed 132 character per line, but not more. Note that this includes comments.</p> </li> <li> <p>Indentation rules:</p> Code feature Num. of indentation characters program indentation 2 type definition 2 do loops 2 if constructs 2 continuation 5 (with leading &amp;) all directives 0 </li> <li> <p>Always use <code>IMPLICIT NONE</code> and <code>PRIVATE</code>/<code>PUBLIC</code> once only in modules header.</p> </li> <li> <p>Do not add <code>USE</code> statements after <code>CONTAINS</code>.</p> </li> <li> <p>Fortran keywords should be in capital letters with the exception of <code>len</code>, <code>in</code>, <code>out</code>, and <code>inout</code>.</p> </li> <li> <p>Do not use tabs, deprecated, or obsolete features.</p> </li> <li> <p>Do not overspecify declarations - especially if standard types are expected.</p> </li> </ol>"},{"location":"development/#python-code","title":"Python Code","text":""},{"location":"development/#logging_1","title":"Logging","text":"<p>In case you want to add some additional prints in EXTPAR, please use the logger described below.</p> <p>CALL the built-in logger-functions in order to print messages or variables in the specific logfile of each EXTPAR executable. The logger can print variables as well as strings. Use formatted strings (<code>f'</code>) in case you want to combine variables and strings. The logger has 4 different levels of messages to print:</p> <ol> <li> <p><code>logging.debug(your_message)</code>: Mean/Max/Min of variables needed for development, more detailed information about code execution.</p> </li> <li> <p><code>logging.info(your_message)</code>: info-prints for better orientation during code execution, variables or other stuff.</p> </li> <li> <p><code>logging.warning(your_message)</code>: warnings, like wrong namelist-inputs, unsupported NetCDF versions or problems with some data points.</p> </li> <li> <p><code>logging.error(your_message)</code>: errors that occur during I/O, allocation or wrong namelist parameters, that requires an abort of EXTPAR. The programm does not stop automatically after the call of logging.error, so a <code>raise</code> follows the logging.error()</p> </li> </ol> <p>Default logging level is info, so only messages from <code>logging.info()</code>, <code>logging.warning()</code> and <code>logging.error()</code> are written to the logfile. Adjust the level of the logger right at the beginning of each Python executable to <code>level=logging.DEBUG</code> to also print <code>logging.debug()</code>.</p>"},{"location":"development/#coding-rules-and-best-practices_1","title":"Coding rules and best practices","text":"<p>The Python code needs to fulfill the Pep8 coding standard . A GitHub action automatically formats Python code for you.</p>"},{"location":"release_notes/","title":"Release notes","text":"<p>For the latest release notes, please see our GitHub webpage .</p>"},{"location":"release_notes/#514","title":"5.14","text":"<ul> <li>New buffer script <code>extpar_cdnc_to_buffer</code> for ICON</li> <li>Cloud droplet number concentration from the cloud optical depth and effective radius</li> <li>Input data:<ul> <li>modis_cdnc_climatology_Q06.nc</li> </ul> </li> </ul>"},{"location":"release_notes/#513","title":"5.13","text":"<ul> <li>New buffer script <code>extpar_edgar_to_buffer</code> for ICON</li> <li>Global emission data for black carbon, organic carbon and sulfur dioxide</li> <li>Input data:<ul> <li>EDGARv6.1_BC_2018_TOTALS.0.1x0.1.nc</li> <li>EDGARv6.1_OC_2018_TOTALS.0.1x0.1.nc</li> <li>EDGARv6.1_SO2_2018_TOTALS.0.1x0.1.nc</li> </ul> </li> <li>Fix albodo for glacier points</li> <li>Changes the following fields for ICON setups<ul> <li>ALB</li> <li>ALNID</li> <li>ALUVD</li> <li>FOR_D</li> <li>FOR_E</li> <li>LAI_MX</li> <li>PLCOV_MX</li> <li>ROOTDP</li> <li>SOILTYP</li> <li>ROOTDP</li> <li>URBAN</li> </ul> </li> </ul>"},{"location":"release_notes/#512","title":"5.12","text":"<ul> <li>New landuse data set Ecoclimap Second Generation</li> <li>Namelist switch <code>i_landuse_data=6</code> in <code>INPUT_LU</code> </li> <li>Set <code>l_terra_urb=.true.</code> in <code>INPUT_LU</code> to process additional urban fields</li> <li>Corresponding input-data set is <code>ECOCLIMAP_SG.nc</code></li> <li>Assign more landuse classes (previously \"undefined\") for Corine</li> <li>Changes the following fields<ul> <li>SOILTYP</li> <li>FR_LAND</li> <li>PLCOV_MX</li> <li>LAI_MX</li> <li>RSMIN</li> <li>URBAN</li> <li>FOR_D</li> <li>FOR_E</li> <li>SKC</li> <li>EMIS_RAD</li> <li>ROOTDP</li> <li>Z0</li> <li>NDVI_MAX</li> <li>FR_LAKE</li> <li>DEPTH_LK</li> <li>AHF</li> <li>ISA</li> <li>NDVI</li> <li>ALNID</li> <li>ALUVD</li> <li>NDVI_MRAT</li> <li>LU_CLASS_FRACTION</li> <li>ALB</li> </ul> </li> <li>New buffer script <code>extpar_hwsdART_to_buffer</code></li> <li>Standalone executable, output not processed by consistency_check</li> <li>Namelist <code>INPUT_hwsdART</code> defines key parameters</li> <li>Input data: HWSD0_USDA.nc</li> <li>Problems with git-lfs prohibit the data to be provided on Levante</li> </ul>"},{"location":"release_notes/#511","title":"5.11","text":"<ul> <li>Remove ecoclimap (ilanduse=4) from extpar_landuse_to_buffer</li> <li>Introduction of GitHub actions</li> <li>Format code each time a .py-file is pushed to repo</li> <li>Test if docs (.tex-file) is still buildable each time it is changed</li> <li>Attach docs (.pdf) as artifact to each git tag</li> <li>Remove misleading code for extpar_topo_to_buffer</li> <li>Orographic smoothing for Icon aborts Extpar</li> <li>Remove dead code parts in mo_agg_topo_icon</li> <li>Installation of Extpar as Python package</li> <li>Possibility to install all relevant executables and Python scripts as package</li> <li>Adapt import statements in all Python files to work as a package as well</li> <li>Detailed instructions how to install in README</li> <li>Wrapper script for Extpar</li> <li>Only key switches like itope_type or ialb_type need to be specified</li> <li>Automatic generation of namelists</li> <li>Picks the correct topographic input data tiles into INPUT_ORO</li> <li>Runs a batched job for Daint or Levante</li> <li>Wrapper needs same Python environment (PYTHONPATH) as Extpar</li> <li>run <code>WrapExtpar.py -h</code> for more infos</li> <li>Testsuite</li> <li>Add new test for WrapExtpar.py on Daint and Levante</li> <li>Python</li> <li>Use <code>raise</code> instead of <code>sys.exit(1)</code> to abort scripts</li> </ul>"},{"location":"release_notes/#5101","title":"5.10.1","text":"<p>This is a minor release to fix cdo version on Levante * CDO-version fixed to 2.0.5 because later versions exit with non-zero exit status for <code>cdo -V</code></p>"},{"location":"release_notes/#510","title":"5.10","text":"<p>This is a minor release with fixes for Levante at DKRZ, a cleanup of MCH runscripts and a bugfix for in consistency_check * CDO version change from 1.9.10 to 2.0.5 on Levante at DKRZ    - Fields from Python-CDO scripts changed up to 10e-4!    - Many (even large) adjustements of the tolerances in the testsuite    - Result on other machines remain unchanged * Fix for array out-of-bounds with special points outside of target domain * Abort Extpar in consistency check if compiler not GCC * Cleanup and update runscripts for models run at MeteoSwiss</p>"},{"location":"release_notes/#591","title":"5.9.1","text":"<p>This is a minor release to support Levante at DKRZ and drop the support for Intel * Support GCC on Levante * Remove configure-wrappers for Mistral * Remove Intel references in testsuite</p>"},{"location":"release_notes/#59","title":"5.9","text":"<p>This is an intermediate release with OpenMP optimizations, a bugfix for topography and and some cleanup * OpenMP optimizations for domains crossing date-line in the following parts    - extpar_landuse_to_buffer    - extpar_topo_to_buffer * Update runscripts    - ETH domain with Merit topography    - EU-Cordex domain with Globe topography * Cleanup    - Remove all leftovers from old build-system    - Remove output for vertices       - Around 10% speedup</p> <ul> <li>Bugfix: Take last row at dateline into account</li> <li>Last raw data row in mo_agg_topo was ignored</li> <li>Changes the following fields (only in testcase mpim/icon_r2b4)<ul> <li>SSO_GAMMA</li> <li>SSO_OROMAX</li> <li>SSO_OROMIN</li> <li>SSO_SIGMA</li> <li>SSO_STDH</li> <li>SSO_THETA</li> <li>T_CL</li> <li>Z0</li> </ul> </li> </ul>"},{"location":"release_notes/#58","title":"5.8","text":"<p>This is an intermediate release with changes for the upgrade of Piz Daint, support for Merit topography for COSMO and a revised algorithm for SGSL processing * Daint upgrade    - export PMI_NO_PREINITIALIZE=1 to avoid unwanted prints from CDO    - New paths for Python virtual environment:       - Daint: /project/g110/extpar/venv_daint       - Tsa: /project/g110/extpar/venv_tsa * Merit for COSMO    - Enable itopo_type=3 for COSMO grid    - Testing performed by Christian Steger from Hymet-group at ETH-IAC * Revised algorithm for SGSL preprocessing    - Infer values of boundary points for SGSL    - Deactivate SGSL for ASTER due to inconsistencies. For detailed information see the PR .</p>"},{"location":"release_notes/#574","title":"5.7.4","text":"<p>This is a minor release with an adaption in the SSO-computation and replacement of ksh with bash * Revised SSO for ICON    - Experiments at DWD showed an improvement of model results with different SSO-thresholds, see this wiki entry  for more information.    - Lowering of threshold from 10.0 to 1.0 changes the following fields       - SSO_GAMMA       - SSO_OROMAX       - SSO_OROMIN       - SSO_SIGMA       - SSO_STDH       - SSO_THETA       - topography_c (only in testcase mpim/icon_r2b4)</p> <ul> <li>Replace ksh with bash in runscripts to prepare for future linux-distributions</li> </ul>"},{"location":"release_notes/#573","title":"5.7.3","text":"<p>This is a minor release with two technical improvements. * Python-CDO    - Automatic detection if CDO contains thread-safe HDF5 library * extpar_topo_to_buffer    - Reduce memory usage for option lsubstract_mean_slope=.TRUE.</p>"},{"location":"release_notes/#572","title":"5.7.2","text":"<p>This is a minor release with an update for the Python environment on Mistral and refactored docs. * Python on Mistral   - Replace anaconda3/bleeding_edge with python3/unstable * Docs   - Remove outdated documentation   - Make docs about testsuite and compilation more comprehensive   - Quickstart for all supported machines</p>"},{"location":"release_notes/#571","title":"5.7.1","text":"<p>This is a minor release with two bugfixes, one for the build-system and one for extpar_topo_to_buffer. * Build-system:   - Install Python-CDO script in bin-folder directly in Makefile   - Out-of-source build include Python-CDO scripts as well  * extpar_topo_to_buffer:    - Abort Extpar for itopo_type = 3</p>"},{"location":"release_notes/#57","title":"5.7","text":"<p>This is an intermediate release that introduces two Python-CDO scripts, modifications for reduced memory usage for non-global grids and a bugfix for the CAMS-aersosol dataset. * extpar_isa_to_buffer    - Replace Fortran code with Python-CDO    - Change in results for fields         - Impervous Surface Area (ISA)    - Read the users guide for detailed information about details of the implementation of extpar_isa_to_buffer * exptar_ahf_to_buffer    - Replace Fortran code with Python-CDO    - Change in results for fields       - Antropogenic Heat Flux (AHF)    - Read the users guide for detailed information about details of the implementation of extpar_ahf_to_buffer * Reduce memory usage for Python-CDO    - Automatic determination of the extent of the target grid    - Use CDO operator -sellonlat to read subset of input data * Bugfix for CAMS dataset    - Remove assertion for GCC-compiler    - Fix wrong dimensions in meta-data for the ICON-grid</p>"},{"location":"release_notes/#56","title":"5.6","text":"<p>This is an intermediate release that introduces a new topography dataset and the CAMS-aerosol climatologies,  OpenMP support for CSCS-machines, enhanced testing on CSCS-machines, a script to extract the input-data from namelist,  progress bars for logfiles of extpar_topo_to_buffer and consistent names for all logfiles.</p> <ul> <li>Merit/Rema topography</li> <li>Set switch itopo_type = 3 to process Merit-Rema data</li> <li>CAMS aerosol climatology for ICON</li> <li>Set switch iaot_type = 5 to process CAMS-aerosol data</li> <li>Due to an unresolved bug only available for Intel compiler</li> <li>Testsuite</li> <li>Remove COSMO-D2 test from testsuite</li> <li>Enable landuse tests for all supported machines</li> <li>All tests run on 12 OpenMP threads on Piz Daint and Tsa for COSMO and ICON</li> <li>Introduce the script extract_inputfiles_from_namelist.py for faster data access at CSCS. It is recommended to use this skript for your own Extpar runs as well.</li> <li>Logging</li> <li>Progress bar (0% to 100%) for topography processing</li> <li>Change logfile-name for extpar_consistency_check to extpar_consistency_check.log</li> </ul>"},{"location":"release_notes/#551","title":"5.5.1","text":"<p>This is a minor release that fixes the inconsistent usage of netCDF versions across Extpar and small documentation changes.</p> <ul> <li>Bugfix netCDF versions</li> <li>Use netCDF version passed via NETCDF_OUTPUT_FILETYPE also for ICON grids (CDI-interface)</li> <li>Documentation changes</li> <li>Put Jonas Jucker as source code administrator</li> </ul>"},{"location":"release_notes/#55","title":"5.5","text":"<p>This is an intermediate release that brings enhanced namelist parsing for the Python-CDO scripts, a new Python-CDO script extpar_era_to_buffer.py to replace the former way of remapping ERA-climatologies using Icontools, a more sophisticated tolerance checker to allow specific roundoff for each test and variables, support NetCDF5 and new default NetCDF 4, fixes for high-resolution grid exceeding integer value range and some minor bugfixes for Piz Daint related to HDF5. * exptar_era_to_buffer    - 4 fields processed       - Sea surface temperature (T_SEA)       - 2m land temperature (T_2M_CLIM)       - Geometric height (TOPO_CLIM)       - Snow water equivalent (W_SNOW)    - New namelist-parameter iera_type defines type of ERA input data used, either ERA-I or ERA-5    - extpar_consistency_check checks for namelist INPUT_ERA to determine if ERA-climatologies come from Python-CDO or Icontools    - Using extpar_era_to_buffer.py changes fields, a detailed review of changes  was performed by J\u00fcrgen Helmert from DWD       - W_SNOW       - TOPO_CLIM       - T_SEA       - T_2M_CLIM    - Read the users guide for detailed information about how extpar_era_to_buffer is integrated into the existing workflow * Enhanced namelist parsing for Python-CDO    - Line starting with ! ignored as expected from Fortran code * Bugfixes for Piz Daint    - -L option for all CDO commands    - Disbable HDF5 file locking due to problems reading some input data * Improved tolerance testing in testsuite    - Tolerances can now be defined separate for each test and variable for example in tolerance file * Support for NetCDF 5   - NetCDF 4 replaces netCDF 3 as default   - Value of environment variable NETCDF_OUTPUT_FILETYPE sets version: NETCDF3, NETCDF4 or NETCDF5 * Modified netCDF-interface functions to allow write of fields with dimesions exceeding default integer value range </p>"},{"location":"release_notes/#541","title":"5.4.1","text":"<p>This is an intermediate release that brings two lradtopo-parameters for Icon, better user feedback for the shell-commands launched in the Python-scripts, a bugfix in exptar_albedo_to_buffer.py, a configure script for O3 (ETHZ) and small technical improvements to the Code. * HORIZON and SKYVIEW fields for the Icon grid    - 4 new namelist-parameter       - radius -&gt; defines the considered horizontal distance for the HORIZON field       - min_circ_cov -&gt; defines the level of detail of the search-algorithm for performance reasons       - max_missing -&gt; defines upper treshold for the allowed missingness at the boundary of the domain       - itype_scaling -&gt; choose the type of scaling for SKYVIEW to account for anisotropic behaviour of IR-radiation     - Read the users guide for detailed information about the difference between the COSMO and the ICON implementation</p> <ul> <li>Refactor function launch_shell by using subprocess.PIPE, providing output even when command crashes</li> <li>Correct bug for ialb_type=1 or 2 during netcdf write</li> <li>Configure script for O3 at ETHZ, not regularly tested with Jenkins</li> <li>Change link to CDI-submodule, to allow access for people witout DKRZ account</li> <li>Split chained CDO-operators into two steps to prevent crashes on Piz  Daint</li> </ul>"},{"location":"release_notes/#54","title":"5.4","text":"<p>This is a major release that introduces a rewrite of 4 Extpar programmes in Python, a common git-LFS input data repository, a new build-system, 2 additional landuse data sets, CDI-library for icon grids in consistency check, mmap-caching for consistency check for less memory usage, some small improvements in the Fortran code and some minor changes in the testsuite.</p> <ul> <li>Rewrite of 4 Extpar programmes in Python</li> <li>Modules extpar_alb_to_buffer.py, extpar_cru_to_buffer.py, extpar_emiss_to_buffer.py and extpar_ndvi_to_buffer.py</li> <li>Small changes of the fields compared to the former Fortran implementation due to different interpolation methods, especially at the coastlines</li> <li>Fields changed:<ul> <li>NDVI, NDVI_MAX, NDVI_MRAT</li> <li>ALB_SAT, ALB_DRY</li> <li>ALB, ALUVD, ALNID</li> <li>T_CL</li> <li>EMISS_RAD</li> </ul> </li> <li>A review  involving users from DWD, MCH, MPIM and ETH took place to ensure the correctness of all fields changed</li> <li>All Python programmes read from the same namelist file namelist.py containing Python dictionaries for each Extpar program.</li> <li> <p>Support of the old and coarse data (it_cl_type = 2) in extpar_cru_to_buffer expires and is replaced the following:</p> <ul> <li>it_cl_type = 2 aggregates the coarse data over sea and the fine data over land</li> <li>it_cl_type = 1 aggregates the fine data over land, sea points are not considered</li> <li>For aggregation of the coarse data over land and sea only, use Extpar 5.3 or older</li> </ul> </li> <li> <p>Read the users guide for detailed information about the rewritten programmes.</p> </li> <li> <p>git-LFS input data repository</p> </li> <li>All input data that can be processed with Extpar is stored in a unified data repository extpar-input-data </li> <li>Move all useful scripts and informations from raw_data_tools to the data repository hosted at DKRZ.</li> <li>Remove folder raw_data_tools from Extpar repository</li> <li>Some fields are renamed for better understanding, so please check your runscripts to adapt the new names.</li> <li>Location on CSCS: /store/c2sm/extpar_raw_data/linked_data</li> <li>Location on Mistral: /work/pd1167/extpar-input-data/linked_data</li> <li>New build-system  </li> <li>New system follows the configure/make/make install paradigm</li> <li>Out-of-source build supported</li> <li> <p>4 basic steps to compile Extpar into binaries:</p> <ul> <li>Run configure.your_machine.your_compiler</li> <li>source modules.env</li> <li>make or make -j 4 (for faster compilation)</li> <li>Kesch at CSCS is no longer supported</li> </ul> </li> <li> <p>Corine landuse data</p> </li> <li>Additional landuse data set covering Europe</li> <li>Can only be used in combination with GLOBCOVER (i_landuse_data=1)</li> <li>Set switch l_use_corine=.true. in namelist lu_raw_data to aggregate the new data set</li> <li> <p>The corine landuse data set is only tested on Mistral at DKRZ</p> </li> <li> <p>ECCI landuse data</p> </li> <li>Global landuse data set split in 6 tiles</li> <li>Set switch i_landuse_data=5, ntiles_globcover=6 and ilookup_table_lu = 1 in namelist lu_raw_data to aggregate the new data set</li> <li> <p>The ECCI landuse data is only tested on Mistral at DKRZ</p> </li> <li> <p>Enhanced testsuite</p> </li> <li>Icon test for DWD for all compilers</li> <li>Jenkins on Mistral, Tsa and Daint</li> <li>Convert testsuite src-code from Python2 to Python3</li> <li>Pep8-Coding style test for Python code</li> <li>Allow round-off for certain fields in output</li> <li> <p>Copy all required files from namelistdir (icon grids, clim-fields and Python-files) through testsuite itself</p> </li> <li> <p>CDI library for icon grids</p> </li> <li>CDI  write routine replaces write_netcdf_icon_grid routine</li> <li>Output of icon grids always involves CDI, output without CDI no longer supported</li> <li>CDI contained as a git submodule inside the Extpar repository</li> <li> <p>See compile_run for instructions to clone Extpar from GitHub correctly</p> </li> <li> <p>Mmap-caching</p> </li> <li>allows run of Extpar on machines with only little memory</li> <li>new logical parameter l_use_array_cache = .true. * in namelist file *INPUT_CHECK activates mmap-caching</li> <li>Bitwise-identical with and without mmap-caching</li> <li> <p>Only supported and tested for GCC compiler</p> </li> <li> <p>Fortran Code changes</p> </li> <li>Remove all filename_max from INTENT(IN)</li> <li>Output of COSMO/ICON netCDF-files in the buffer modules no longer supported</li> <li>Remove all unused modules/programmes replaced by Python modules</li> <li>Remaining code still needed in Fortan now contained in modules mo_python_data.f90, mo_python_routines.f90, and mo_python_tg_fields.f90</li> </ul>"},{"location":"release_notes/#53","title":"5.3","text":"<p>This is an intermediate release that reduces code complexity for topo_to_buffer.exe, enhances the testing for INTEL compiler and further cleans the code</p> <ul> <li>Merge sgsl_to_buffer into topo_to_buffer</li> <li>New namelist &amp;oro_runcontrol in INPUT_ORO containing lcompute_sgsl</li> <li>For users of former sgsl_to_buffer.exe, namelist &amp;sgsl_io_extpar now moved to INPUT_ORO, containing the new parameter lpreproc_oro</li> <li> <p>The functionality is kept by default for all newly introduced namelist parameters, so for the same workflows as before only change lcompute_sgsl</p> </li> <li> <p>Testsuite</p> </li> <li>Additional check for compiler warning of GCC,INTEL and NAG</li> <li>Unify runscripts for COSMO and ICON</li> <li>Slightly different domain for COSMO1, reducing the required number of ASTER tiles to only 1</li> <li> <p>Add references for INTEL in a seperate directory in data</p> </li> <li> <p>Cleanup</p> </li> <li>Initialize logicals in extpar_consistency_check properly to prevent bugs</li> <li>Remove hardcoded filename in emiss_to_buffer</li> <li>Finalize logging and coding standard as described in developers guide</li> </ul>"},{"location":"release_notes/#521","title":"5.2.1","text":"<p>This is a minor release containing a bug fix and a small feature addition.  * Bug fix for ICON/COSMO file- and variable name mismatch in topography calculation  * Add Extpar version number (pulled from git release number) to output NetCDF file</p>"},{"location":"release_notes/#52","title":"5.2","text":"<p>This is an intermediate release introducing extpar_emiss_to_buffer, an improved logging, enhanced error checking during I/O and a lot of clean-up and formatting</p> <ul> <li>New Extpar executable emiss_to_buffer</li> <li>Aggregates CAMEL emissivity data to the target grid</li> <li> <p>Two raw datasets available (full range and only long-wave radiation)</p> </li> <li> <p>Consistent logger for all Extpar executables</p> </li> <li>Three levels of messages: info, warning and error</li> <li> <p>Each Extpar executable write to its own logfile</p> </li> <li> <p>Clean-up and formatting of all src-files</p> </li> <li>Remove all unused variables and USE-statements</li> <li>Remove all unused dummy arguments in subroutines</li> <li> <p>Implement formatting according the coding-guidelines for Extpar</p> </li> <li> <p>Make all precisions consistent</p> </li> <li>Remove i8 from Extpar, instead make all INTEGER(KIND=i4)</li> <li> <p>Change all REAL to REAL(KIND=wp), wp is defined in mo_kind</p> </li> <li> <p>Small changes in some fields due to fix of implicit type conversion during runtime</p> </li> <li>Z0, max difference ~10^(-7)</li> <li> <p>DEPTH_LK, max difference ~10^(-6)</p> </li> <li> <p>Enhanced error checking during I/O</p> </li> <li>All namelist I/O checked, abort of Extpar in case of incorrect (typos, wrong variables, etc,) namelists</li> </ul>"},{"location":"release_notes/#512_1","title":"5.1.2","text":"<p>This is a minor release containing a few bug fixes.  * Fix build environment on Kesch  * Add missing definition of skinc_lu meta data when ECOCLIMAP dataset is chosen. </p>"},{"location":"release_notes/#511_1","title":"5.1.1","text":"<p>This is a minor release containing a few bug fixes.  * Fix read of l_use_glcc landuse calculation for COSMO runs.  * Fix unitialized logical flag to trigger scale separation in topography calculation.  * Reactivate all cosmo tests from testsuite on Kesch.</p>"},{"location":"release_notes/#51","title":"5.1","text":"<p>This is an intermediate release containing some bug fixes and some minor developments.  </p> <ul> <li>Changes to Jenkins and the automated testing:  </li> <li>Fix Mistral setup so that code runs on compute nodes instead of login nodes</li> <li>Fix Mistral setup so that intel compiler can be tested.  Note that only run success      is checked for the intel compiler; the results are not yet tested.  </li> <li> <p>Fix NAG compiler setup so that only compilation, not testing is done, because      testing is too time consuming.  </p> </li> <li> <p>Bug fix for iaot_type = 4 (MACv2 aerosols).  The code had not been correctly imported from version 4.0.</p> </li> <li> <p>Contributions from DWD including:</p> </li> <li>DWD versions of the python and shell replacement scripts for ndvi, albedo, and cru</li> <li>DWD bug fix for the albedo calculation</li> <li> <p>DWD bug fix for incorrect glacier points</p> </li> <li> <p>New output variable skin conductivity (SKC) developed by Jan-Peter Schulz.  Skin conductivity is calculated from the landuse data.  </p> </li> </ul>"},{"location":"release_notes/#504","title":"5.0.4","text":"<p>This is a minor release containing a few bug fixes.</p> <ul> <li> <p>Bug fix for problems when soil_type=3 is used.  The code had not been correctly imported from version 4.0  </p> </li> <li> <p>Bug fix adding missing NetCDF get_varid call when more than one GLOBCOVER tile is used.  </p> </li> </ul>"},{"location":"release_notes/#503","title":"5.0.3","text":"<p>This is a minor release containing a bug fix.  </p> <ul> <li>Bug fix for incorrect global attributes in output NetCDF file.  </li> </ul>"},{"location":"release_notes/#502","title":"5.0.2","text":"<p>This is a minor release containing a bug fix.</p> <ul> <li>Bug fix for incorrect subroutine argument usage in mo_agg_isa.f90.  </li> </ul>"},{"location":"release_notes/#501","title":"5.0.1","text":"<p>This is a minor release fixing a few bugs and some documentation.</p> <ul> <li>Bug fix to remove too many characters in write statement (mo_logging.f90)</li> <li>Bug fix for unitialized variable ntiles_globcover (mo_landuse_routines.f90, extpar_consistency_check.f90, and extpar_landuse_to_buffer.f90)</li> <li>Remove unnecessary libraries in Options.daint</li> <li>Fix typos in README.compile_run</li> </ul>"},{"location":"release_notes/#50","title":"5.0","text":"<p>This release represents a merge of the Extpar official version 4.0 code with the DWD-Extpar version 2.10. </p>"},{"location":"release_notes/#build-mechanism","title":"Build Mechanism","text":"<ul> <li>Added Options file for compiling on LCE with Intel compiler</li> <li>Added Options files for compiling on Mistral with GCC, NAG, and Intel compilers</li> <li>Added Options files for compiling on Mac OS with the GCC compiler</li> <li>Updated Options file for compiling on o3 at ETH with PGI compiler</li> <li>Update bin/gen_info.sh for compatibility with git</li> </ul>"},{"location":"release_notes/#run-scripts","title":"Run scripts","text":"<ul> <li>Minor adaptations to run scripts to be compatible with new version</li> <li>Addition of MPI ICON run script</li> </ul>"},{"location":"release_notes/#testing","title":"Testing","text":"<ul> <li>Addition of cosmo-dwd and icon tests to testsuite.</li> <li>Update of Jenkins build and test scripts.</li> <li>Add testsuite run scripts for mpi and dwd on mistral.</li> <li>Update of testsuite references.</li> </ul>"},{"location":"release_notes/#code-changes","title":"Code changes","text":""},{"location":"release_notes/#albedo-calculation","title":"Albedo calculation:","text":"<ul> <li>Added bin/cdo2alb-buffer.py and extpar_alb_to_buffer.sh to replace slow and incorrect albedo calculation for high resolution ICON model grids</li> </ul>"},{"location":"release_notes/#topography-calculation","title":"Topography calculation:","text":"<ul> <li>Added namelist parameter: lsubtract mean_slope</li> <li>Move mo_agg_topo to mo_agg_topo_icon and mo_agg_topo_cosmo</li> <li>Bug fix in mo_topo_sso- changes results of sso_sigma slightly</li> </ul>"},{"location":"release_notes/#soil-calculation","title":"Soil calculation:","text":"<ul> <li>Additional HWSD calculation for deep soil</li> </ul>"},{"location":"release_notes/#ndvi-calculation","title":"NDVI calculation:","text":"<ul> <li>Added bin/cdo2ndvi-buffer.py and extpar_ndvi_to_buffer.sh to replace slow and incorrect NDVI calculation for high resolution ICON model grids</li> </ul>"},{"location":"release_notes/#climatological-2m-temperature-calculation","title":"Climatological 2M temperature calculation:","text":"<ul> <li>Added bin/cdo2t_cl-buffer.py and extpar_cru_to_buffer.sh to replace slow and incorrect TCLIM calculation for high resolution ICON model grids</li> <li>Added namelist parameter: ltcl_merge</li> </ul>"},{"location":"release_notes/#flake-calculation","title":"Flake calculation:","text":"<ul> <li>Added namelist parameter: lflake_correction.</li> </ul>"},{"location":"release_notes/#consistency-check","title":"Consistency check:","text":"<ul> <li>[Changes results] Included lower limit for roughness length</li> <li>ERA-I SST and T2M temperature for ICON model</li> </ul>"},{"location":"release_notes/#grib-output-not-supported","title":"Grib output NOT supported","text":""},{"location":"release_notes/#gme-model-not-supported","title":"GME model NOT supported","text":""},{"location":"release_notes/#changes-in-results","title":"Changes in Results","text":"<p>Due to the large amount of changes in the code in this release, there are many differences in the resulting external parameter fields generated by the release 5.0 code compared to the fields generated by older Extpar codes.  The only code change in this release that deliberately changed the results was the addition of a lower limit for roughness length, which is 1e-6.  Otherwise, any changes in results that can be seen came directly from bug fixes to the code, and as such most of them are small and are not expected to change results in the COSMO or ICON model runs.  Some of these changes in results are examined in the next two sections.  </p>"},{"location":"release_notes/#extpar-version-40-to-extpar-version-50","title":"Extpar version 4.0 to Extpar version 5.0","text":"<p>The technical testsuite in Extpar was used to compare the external parameter fields from Version 4.0 and Version 5.0 for three different MeteoSwiss operational setups for COSMO and a climate setup for COSMO-CLM.  </p>"},{"location":"release_notes/#cosmo-7-globe-topography-input","title":"COSMO 7, globe topography input","text":"<p>For the COSMO7 MCH setup using the globe topography data set, changes in the results smaller than 1e-6 can be seen for several variables, including the aerosol variables, albedo variables, HORIZON, and SSO_SIGMA.  Larger changes on the order of 3 degrees can be seen in the SSO_THETA variable;  these are due to a bug fix in this release, and are expected.  Finally, roughness length is different as well due to the introduction of the lower limit value of 1e-6.  </p>"},{"location":"release_notes/#cosmo-7-aster-topography-input","title":"COSMO 7, aster topography input","text":"<p>For the COSMO7 MCH setup using  the aster topography data set, the changes in the results are less than 5e-7, and occur in the aerosol, HORIZON, and SSO_SIGMA variables.  </p>"},{"location":"release_notes/#cosmo-1-aster-topography-input","title":"COSMO 1, aster topography input","text":"<p>For the COSMO1 MCH setup using the aster topography data set, the changes in the results are less than 4e-5, and occur in the aerosol, HORIZON, SKYVIEW, and T_CL variables.  </p>"},{"location":"release_notes/#cosmo-cm-climate-setup","title":"COSMO-CM climate setup","text":"<p>For the COSMO-CLM climate setup using the globe topography data set, changes in results smaller than 3e-8 can be seen in the SSO_SIGMA and SSO_STDH variables.  Larger changes on the order of 3 degrees can be seen in the SSO_THETA variable;  these are due to a bug fix in this release, and are expected.  Due to another bug fix, the ALB_SAT and ALB_DRY variables have changed results on the order of .2.  Finally, roughness length is different as well due to the introduction of the lower limit value of 1e-6.  </p>"},{"location":"release_notes/#dwd-extpar-version-210-to-extpar-version-50","title":"DWD Extpar version 2.10 to Extpar version 5.0","text":"<p>Comparisons of the COSMO D2 setup used operationally by DWD were carried out to compare the current operational Extpar code (DWD version 2.10) with the new release 5.0.  This comparison showed no significant differences in the generated external parameter fields.  Get more details of this comparison here</p>"},{"location":"testing/","title":"Testing","text":"<p>EXTPAR is tested with an adapted version of the COSMO technical testsuite .</p>"},{"location":"testing/#run-tests","title":"Run Tests","text":"<p>First step is to compile the code following the instructions in Compile and Run.</p>"},{"location":"testing/#docker","title":"Docker","text":"<pre><code>docker run extpar bash -c \"/workspace/test/jenkins/test_docker.sh\"\n</code></pre>"},{"location":"testing/#levante","title":"Levante","text":"<pre><code>cp bin/* test/testsuite/bin/.\ncd test/testsuite\n./data/get_data.sh\nsbatch submit.levante.sh\n</code></pre> <p>The results of the testsuite can be found in file testsuite.out</p> <p>An example output could look as follows: </p>"},{"location":"testing/#testlists","title":"Testlists","text":"<p>There are many different testlist, each containing a set of tests for different setups, compiler or models:</p>"},{"location":"testing/#gcc","title":"GCC","text":"<ul> <li>COSMO </li> <li>ICON </li> <li>Landuse </li> </ul>"},{"location":"testing/#tolerances","title":"Tolerances","text":"<p>It is possible to define an optional tolerance threshold for each test and each field. To allow deviations for the test icon_d2 for example, just dit the the tolerances file .</p> <p>The syntax is as follows:</p> <pre><code>PARAMETER, abs_diff\nNDVI, 9.0e-08\nW_SNOW, 5.0e-05\n</code></pre>"},{"location":"testing/#add-a-new-test","title":"Add a New Test","text":"<ol> <li> <p>Modify the <code>testlist.xml</code> file to add the new test. Alternatively, you could also add a new      testlist XML file (with a new name).  The testlist which is run can be chosen from the testsuite     command line.  </p> </li> <li> <p>Make a folder in the data folder for the new test containing the <code>INPUT_*</code> files and the namelist.py for the Python-CDO modules.  </p> </li> <li> <p>Send any binary reference files to upload to the ftp site to the source code administrator. </p> </li> </ol>"},{"location":"user_manual/","title":"User and Implementation Guide","text":"<p>Hermann Asensio / Martina Messmer / Daniel L\u00fcthi / Katie Osterried / Jonas Jucker / Jacopo Canton / Philipp Sommer / J\u00fcrgen Helmert / Michael J\u00e4hn</p> <p>This documentation provides an overall description of the EXTPAR software, provides detailed information on specific modules, current limitations and the namelist input.</p> <p>For the sake of completeness, the latest EXTPAR documentation (v5.14)  that was created from the original LaTeX file, can be downloaded here.</p>"},{"location":"user_manual/SUMMARY/","title":"SUMMARY","text":"<ul> <li>Home</li> <li>Overall Description</li> <li>Software Modules</li> <li>Fortran Modules</li> <li>Python Modules</li> <li>Current Limitations</li> <li>Namelist Input</li> </ul>"},{"location":"user_manual/user_manual_01_overall_description/","title":"Overall Description","text":"<p>Numerical Weather Prediction (NWP) models and Climate models require geographical localized datasets like the topographic height of the earth surface, the plant cover, the distribution of land and sea and, dependent on the schemes used, a variety of other external parameters.</p> <p>The EXTPAR software system (EXTPAR - External Parameter for Numerical Weather Prediction and Climate Application) is able to generate external parameters for the different models COSMO and ICON. The software can run on a UNIX or Linux system where the raw data is stored. It allows operators (experienced users) running the scripts to create new external parameters controlled by user specifications like the model domain.</p> <p>The following steps are performed for the generation of external parameters:</p> <ol> <li> <p>The target grid has to be specified. The supported target grids are</p> <ul> <li>Rotated and non-rotated longitude-latitude grid (COSMO)</li> <li>Icosahedral Triangular grids (ICON) with optionally higher     resolution in selected regions ('local zooming')</li> </ul> </li> <li> <p>The different raw data sets are aggregated to the target grid     considering all raw data elements which are within the target grid     element. If the target grid has a higher resolution than the input     grid on which the raw data is available either an interpolation is     performed or the target grid is filled with the nearest neighbor,     but sub-grid scale statistical calculations (e.g. subgrid scale     variance of orograhic height) are dismissed.</p> </li> <li> <p>All the different external parameter sets have to be checked for     consistency against each other. In case of conflicts default values     are set automatically. In the NetCDF output, information on the     input data and the processing software is given.</p> </li> </ol>"},{"location":"user_manual/user_manual_01_overall_description/#main_input","title":"Input Raw Datasets","text":"<p>The information for the external parameters is aggregated from various raw datasets for land use data, orography or soil data, see table below for a detailed list of the raw datasets.</p> <p>The input data for EXTPAR is stored in a git-LFS repository at https://gitlab.dkrz.de/extpar-data/extpar-input-data . Instructions for downloading the whole repository or updating with new datasets can be found in the git-LFS repository. For access to the input data repository, contact the current EXTPAR source code administrator.</p> <p></p> Dataset Source Resolution GLOBE orography NOAA/NGDC 30'' ASTER orography (limited domain: 60\u00b0N - 60\u00b0S) METI/NASA 1'' MERIT/REMA orography Composite DEM 3'' (90m) Globcover 2009 ESA 10'' GLC2000 land use JRC Ispra 30'' GLCC land use USGS 30'' Ecoclimap-SG land use CNRS and Meteo France 300m ESA CCI-LC ESA 10'' DSMW Digital Soil Map of the World FAO 5' HWSD Harmonized World Soil Database FAO/IIASA/ISRIC/ISSCAS/JRC 30'' HWSD Harmonized World Soil Database USDA KIT 30'' NDVI Climatology, SEAWiFS NASA/GSFC 2.5' CRU near surface climatology CRU University of East Anglia 0.5 degree Aerosol Optical thickness NASA/GISS 4x5 degree (Global Aerosol Climatology Project) AeroCom Global AOD data AeroCom Project 1 degree MACC-II climatological AOD (2003-2012) ECMWF 1.125 degree MACv2 monthly AOD, SSA and ASY data MPI, RHM 1 degree CAMS monthly 3D-climatology 11 types of aerosols ECMWF, RHM 3 degree Global lake database (GLDB) DWD/RSHU/MeteoFrance 30'' MODIS albedo NASA 5' MODIS derived soil albedo values Community Land Model 3.5 30' CAMEL Emissivity NASA 5km EDGAR Emissions European Commission /JRC/PBL 0.1 degree MODIS cloud droplet number climatology Q06 NASA 1 degree <p>Table 1: Input raw datasets</p>"},{"location":"user_manual/user_manual_01_overall_description/#main_output","title":"Output External Parameters","text":"<p>The output fields with the external parameters are shown here:</p> <p></p> External parameter Short name Unit Raw dataset geometrical height HSURF \\(m\\) GLOBE/ASTER/MERIT/REMA geopotential of earth surface FIS \\(m^{2} s^{-1}\\) GLOBE/ASTER/MERIT/REMA standard deviation of subgrid scale orographic height SSO_STDH \\(m\\) GLOBE/ASTER/MERIT/REMA anisotropy of topography SSO_GAMMA 1 GLOBE/ASTER/MERIT/REMA angle between principal axis of orography and global E SSO_THETA 1 GLOBE/ASTER/MERIT/REMA mean slope of subgrid scale orography SSO_SIGMA 1 GLOBE/ASTER/MERIT/REMA surface roughness Z0 \\(m\\) GLC2000, GLOBE/ASTER/MERIT/REMA Slope aspect SLOPE_ASP deg GLOBE/ASTER/MERIT/REMA Slope angle SLOPE_ANG deg GLOBE/ASTER/MERIT/REMA Horizon angles (resolution from 15deg) HORIZON deg GLOBE/ASTER/MERIT/REMA Skyview factor SKYVIEW - GLOBE/ASTER/MERIT/REMA soil texture SOILTYP - DSMW/HWSD fraction of sand FR_SAND % HWSD fraction of silt FR_SILT % HWSD fraction of clay FR_CLAY % HWSD fraction of organic carbon FR_OC % HWSD bulk density BULK_DENS \\(g cm^{-3}\\) HWSD deep soil texture SUBSOILTYP - HWSD deep soil fraction of sand SUB_FR_SAND % HWSD deep soil fraction of silt SUB_FR_SILT % HWSD deep soil fraction of clay SUB_FR_CLAY % HWSD deep soil fraction of organic carbon SUB_FR_OC % HWSD deep soil bulk density SUB_BULK_DENS \\(g cm^{-3}\\) HWSD Fraction of Heavy Clay fr_hcla 1 HWSD_USDA Fraction of Silty Clay fr_silc 1 HWSD_USDA Fraction of Light Clay fr_lcla 1 HWSD_USDA Fraction of Silty Clay Loam fr_sicl 1 HWSD_USDA Fraction of Clay Loam fr_cloa 1 HWSD_USDA Fraction of Silt fr_silt 1 HWSD_USDA Fraction of Silty Loam fr_silo 1 HWSD_USDA Fraction of Sandy Clay fr_scla 1 HWSD_USDA Fraction of Loam fr_loam 1 HWSD_USDA Fraction of Sandy Clay Loam fr_sclo 1 HWSD_USDA Fraction of Sandy Loam fr_sloa 1 HWSD_USDA Fraction of Loamy Sand fr_lsan 1 HWSD_USDA Fraction of Sand fr_sand 1 HWSD_USDA Fraction of Undefined or Water fr_udef 1 HWSD_USDA ground fraction covered by plants max (vegetation period) PLCOV_MX 1 GLC2000/Globcover/ ESA CCI-LC ground fraction covered by plants min (vegetation period) PLCOV_MN 1 GLC2000/Globcover/ ESA CCI-LC ground fraction covered by artificial (urban) areas URBAN 1 GLC2000/Globcover/ ESA CCI-LC ground fraction covered by artificial (urban) areas URBAN 1 GLC2000/Globcover/ESA CCI-LC/ LCZs with TERRA_URB ground fraction covered by deciduous forest FOR_D 1 GLC2000/Globcover/ ESA CCI-LC skin conductivity SKC \\(W m^{-1} K^{-1}\\) Globcover/ESA CCI-LC root depth ROOTDP \\(m\\) GLC2000/Globcover/ ESA CCI-LC leaf area index max(vegetation period) LAI_MX 1 GLC2000/Globcover/ESA CCI-LC leaf area index min (vegetation period) LAI_MN 1 GLC2000/Globcover/ ESA CCI-LC plant resistance PRS_MIN \\(s m^{-1}\\) GLC2000/Globcover/ ESA CCI-LC long wave surface emissivity EMISS_RAD 1 GLC2000/Globcover/ ESA CCI-LC (monthly) normalized differential vegetation index NDVI 1 SEAWIFS Annual maximum of normalized differential vegetation index NDVI_MAX 1 SEAWIFS (monthly) proportion of actual value/ maximum normalized differential vegetation index NDVI_RATIO 1 SEAWIFS (monthly) optical thickness from black carbon aerosol AER_BC 1 GACP (monthly) optical thickness from dust aerosol AER_DUST 1 GACP (monthly) optical thickness from organic aerosol AER_ORG 1 GACP (monthly) optical thickness from SO4 aerosol AER_SO4 1 GACP (monthly) optical thickness from sea salt aerosol AER_SS 1 GACP (monthly) aerosol optical thickness for RG92 spectral bands AOT12 1 MACv2 (monthly) single scattering albedo for RG92 spectral bands SSA12 1 MACv2 (monthly) asymmetry factor for RG92 spectral bands ASY12 1 MACv2 (monthly) layer-integrated mass of Sea Salt with dry radius in the range 0.03-0.5 microns Sea_Salt_bin1 \\(kg m^{-2}\\) CAMS (monthly) layer-integrated mass of Sea Salt with dry radius in the range 0.5-5.0  microns Sea_Salt_bin2 \\(kg m^{-2}\\) CAMS (monthly) layer-integrated mass of Sea Salt with dry radius in the range 5.0-20.0  microns Sea_Salt_bin3 \\(kg m^{-2}\\) CAMS (monthly) layer-integrated mass of Mineral Dust with dry radius in the range 0.03-0.55 microns Mineral_Dust_bin1 \\(kg m^{-2}\\) CAMS (monthly) layer-integrated mass of Mineral Dust with dry radius in the range 0.55-0.9  microns Mineral_Dust_bin2 \\(kg m^{-2}\\) CAMS (monthly) layer-integrated mass of Mineral Dust with dry radius in the range 0.9-20.0  microns Mineral_Dust_bin3 \\(kg m^{-2}\\) CAMS (monthly) layer-integrated mass of hydrophilic Organic Matter Organic_Matter_hydrophilic \\(kg m^{-2}\\) CAMS (monthly) layer-integrated mass of hydrophobic Organic Matter Organic_Matter_hydrophobic \\(kg m^{-2}\\) CAMS (monthly) layer-integrated mass of hydrophilic Black Carbon Black_Carbon_hydrophilic \\(kg m^{-2}\\) CAMS (monthly) layer-integrated mass of hydrophobic Black Carbon Black_Carbon_hydrophobic \\(kg m^{-2}\\) CAMS (monthly) layer-integrated mass of Sulfates Sulfates \\(kg m^{-2}\\) CAMS (monthly) Pressure at base of layer half_level_pressure Pa CAMS Near surface temperature (climatological mean) T_2M_CL \\(K\\) CRU Lake Depth DEPTH_LK \\(m\\) GLDB Lake Fraction FR_LAKE 1 GLDB (monthly) albedo ALB_DIF12 % MODIS (monthly) Near Infrared Albedo ALNID % MODIS (monthly) Ultra Violet Albedo ALUVD % MODIS soil albedo for dry soils ALB_DRY % Community Land Model 3.5 soil albedo for saturated soils ALB_SAT % Community Land Model 3.5 fraction of impervious surface area ISA 1 NOAA, EEA or LCZs with TERRA_URB anthropogenic heat flux AHF \\(W m^{-2}\\) NOAA or LCZs with TERRA_URB subgrid-scale slope parameter S_ORO 1 GLOBE, ASTER, MERIT/REMA EMISS yearly maximum for climatology 1998-2003 EMISS_MAX 1 CAMEL monthly mean EMISS climatology 1998-2003 EMISS 1 CAMEL (monthly) proportion of actual value/maximum normalized differential vegetation index EMISS_MRAT 1 CAMEL Urban paved fraction FR_PAVED 1 LCZs with TERRA_URB Urban building fraction URB_BLDFR 1 LCZs with TERRA_URB Urban building height URB_BLDH \\(m\\) LCZs with TERRA_URB Urban canyon height-to-width ratio URB_H2W 1 LCZs with TERRA_URB Urban shortwave albedo URB_SALB 1 LCZs with TERRA_URB Urban thermal albedo URB_TALB 1 LCZs with TERRA_URB Urban emissivity URB_EMIS 1 LCZs with TERRA_URB Urban heat conductivity URB_HCON 1 LCZs with TERRA_URB Urban heat capacity URB_HCAP \\(J/K\\) LCZs with TERRA_URB Annual black carbon emissions emi_bc \\(kg\\,m^{-2}\\,s^{-1}\\) EDGAR Annual organic carbon emissions emi_oc \\(kg\\,m^{-2}\\,s^{-1}\\) EDGAR Annual sulfur dioxide carbon emissions emi_so2 \\(kg\\,m^{-2}\\,s^{-1}\\) EDGAR Annual ammonia emissions emi_nh3 \\(kg\\,m^{-2}\\,s^{-1}\\) EDGAR Annual nitrogen oxides emissions emi_nox \\(kg\\,m^{-2}\\,s^{-1}\\) EDGAR Monthly cloud droplet number climatology cdnc \\(cm^{-3}\\) MODIS <p>Table 2: Output external parameters</p>"},{"location":"user_manual/user_manual_02_software_modules/","title":"Software Modules","text":""},{"location":"user_manual/user_manual_02_software_modules/#Overview","title":"Overview","text":"<p>The software EXTPAR is composed of thirteen autonomous programmes. Twelve programmes are responsible for aggregating a raw data to the target grid, which is specified by the user. The thirteenth program, the consistency check, is performed in the end. The executables are called <code>extpar_*_to_buffer</code>, whereas the star <code>*</code> stands for ahf (anthropogenic heat flux), aot (aerosol optical thickness), cru (temperature climatology of the Climate Research Unit (CRU)), landuse, topo, ndvi (normalized difference vegetation index), soil, flake (fraction lake), isa (impervious surface area), albedo, emiss (emissivity) and era (ERA climatologies) respectively. In Fig. 1 a schematic representation of EXTPAR is drawn. For the sake of clarity only the topography and land-use path is shown. The same can be applied for the other ten raw data sets. For all these programs there exist namelists. Most of the namelists only contain the name and path of the raw data file and the name of the buffer file, which is later used for the consistency check, and the name of the output of the final external variables.</p> <p>The software modules read from the following namelist files:</p> <ul> <li>INPUT_AOT</li> <li>INPUT_LU</li> <li>INPUT_ORO, INPUT_OROSMOOTH, INPUT_RADTOPO, INPUT_SCALE_SEP</li> <li>INPUT_SOIL</li> <li>INPUT_hwsdART</li> <li>INPUT_FLAKE</li> <li>INPUT_grid_org</li> <li>INPUT_COSMO_GRID or INPUT_ICON_GRID</li> <li>namelist.py</li> </ul> <p>The namelists <code>INPUT_grid_org</code> and either <code>INPUT_COSMO_GRID</code> or <code>INPUT_ICON_GRID</code> are used in all the programs, as they contain the general information of the target grid to which the raw data should be aggregated. The namelist file <code>namelist.py</code> is read by all Python programmes.</p> <p></p> <p> Figure 1: Schematic illustration of the software EXTPAR.</p>"},{"location":"user_manual/user_manual_02_software_modules/#Python-CDO","title":"Hybrid Python-CDO Structure","text":"<p>For three of the external parameters calculated by EXTPAR, namely albedo, NDVI, and the Hadley CRU climatologies, problems appeared with target resolutions much higher than the provided input data set resolutions. The problem is that not all target grid points get assigned a proper value when using the legacy Fortan code and interpolation method.</p> <p>The algorithm used in the legacy Fortran modules aggregates source grid point values onto the target grid where the input data is finer than the target grid and uses bi-linear interpolation to fill the remaining grid points where the input data is sparser than the target grid. However, starting from a 5 km global resolution for the target grid, points can potentially get assigned unreasonable values because of the insufficiency of the bi-linear interpolation algorithm.</p> <p>To resolve this issue, for EXTPAR Version 5.4 a rewrite of those Fortran modules in Python, using the more sophisticated interpolation methods from CDO with support for all grids was conducted. Because the interpolation methods implemented in CDO are faster than those in Fortran for large model grids, emiss_to_buffer is written in Python as well. A rewrite in Python only makes sense for Fortran modules that do simple calculations with the data. These calculations can easily be substituted with CDO-commands in the Python modules. For modules doing complex calculations and providing many namelist parameters the user can define, like extpar_topo_to_buffer or extpar_landuse_to_buffer, a rewrite in Python is not planned.</p> <p>The interpolation algorithms selected are:</p> <ul> <li>albedo distance-weighted average remapping</li> <li>NDVI first order conservative remapping</li> <li>EDGAR first order conservative remapping</li> <li>CDNC first order conservative remapping</li> <li>CRU climatology distance-weighted average remapping</li> <li>emissivity first order conservative remapping</li> <li>ERA climatology first order conservative remapping</li> <li>AHF/ISA bilinear interpolation</li> </ul> <p>The description of the used algorithms can be found via the CDO documentation.</p>"},{"location":"user_manual/user_manual_02_software_modules/#Summary","title":"Summary","text":"<p>The external parameters can be generated by using thirteen programs to aggregate the various raw datasets to the target grid and after this by calling the final program for the important consistency check.</p> <ol> <li> <p>In a first step, the target grid and other parameters have to be     specified by the user in the runscript (see section     Grid Definition for the details).</p> </li> <li> <p>Then the aggregation of the raw datasets listed in Table 1 to the given target grid can be     performed by calling following executables</p> <ul> <li><code>extpar_aot_to_buffer</code></li> <li><code>extpar_cru_to_buffer</code></li> <li><code>extpar_landuse_to_buffer</code></li> <li><code>extpar_topo_to_buffer</code></li> <li><code>extpar_ndvi_to_buffer</code></li> <li><code>extpar_soil_to_buffer</code></li> <li><code>extpar_flake_to_buffer</code></li> <li><code>extpar_alb_to_buffer</code></li> <li><code>extpar_isa_to_buffer</code></li> <li><code>extpar_ahf_to_buffer</code></li> <li><code>extpar_emiss_to_buffer</code></li> <li><code>extpar_hwsdART_to_buffer</code></li> <li><code>extpar_era_to_buffer</code></li> <li><code>extpar_edgar_to_buffer</code></li> </ul> <p>These programs generate intermediate NetCDF files (\"buffer\") with the aggregated data.</p> </li> <li> <p>The executable <code>extpar_consistency_check</code>     reads in the buffer-files, performs an automated consistency check,     and finally generates the output fields listed in     Table 2.</p> </li> </ol> <p>The task of the consistency check that is performed at the end is to find inconsistencies in the soil data, the lake data and the NDVI data. In the soil data problems may appear between the soil type and the land-use, in particular for water and ice grid elements. For the fraction lake, minimal and maximal lake depth must be introduced and some seas such as the Caspian and the Dead Sea as well as Lake Constance must be defined manually. For more information see chapter 3.7.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/","title":"Fortran Modules","text":""},{"location":"user_manual/user_manual_03_fortran_modules/#extpar_topo_to_buffer","title":"extpar_topo_to_buffer","text":""},{"location":"user_manual/user_manual_03_fortran_modules/#short-description","title":"Short description","text":"<p>The program extpar_topo_to_buffer aggregates the orography of the GLOBE, ASTER, or MERIT/REMA dataset to the target grid.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#target-grid-definition","title":"Target grid definition","text":"<p>The first part of this program contains several routines that read the namelists defined in the run script (see  chapter 6 for more information on the run scripts). The first routine (init_target_grid) collects all the information needed to define the target grid with an integrated routine that gathers the variables given in the namelist <code>INPUT_grid_org</code>. The variable igrid_type, which can either be 1 ('ICON') or 2 ('COSMO'), is an integer switch to define the target grid.</p> <p>Then a routine reads the namelist of the corresponding grid, which is either <code>INPUT_ICON_GRID</code> or <code>INPUT_COSMO_GRID</code>, depending on the chosen grid type. The run script contains only one of the two namelists. This must be manually changed by the user. These namelists contain among other variables the resolution of the grid, the user specified domain and the location of the center of the grid (for closer information about the namelists compare chapters 6.2.2 - 6.2.3).  This allows an exact definition of the target grid.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#subgrid-scale-slope","title":"Subgrid-scale slope","text":"<p>The namelist INPUT_ORO contains the parameter lcompute_sgsl, to determine whether SGSL should be calculated from the respective raw topography data. Formerly this was done in a separate executable extpar_sgsl_to_buffer.exe. From Release 5.3 onwards, the SGSL calculation was incorporated into the execututable 'extpar_topo_to_buffer`. As an intermediate step, the SGSL is written out to NetCDF, one separate file for each raw topography tile is required. In case the preprocessed SGSL NetCDF are already available, setting the parameter lpreproc oro= .false., deactivates the preprocessing, but not the aggregation of SGSL to the target grid. We recommend to only do the preprocessing for the GLOBE dataset, because the computational cost for the ASTER or MERIT/REMA dataset is very high and no validation has taken place for this dataset.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#topographic-correction-for-radiation","title":"Topographic correction for radiation","text":"<p>In a second step, the namelist <code>INPUT_RADTOPO</code> is read. It contains the information if the user desires the calculation of the topographical corrected radiation parameters or not. If the switch is set to .TRUE. a border is added to the COSMO domain, as the computations need grid points beyond the edges of the normal domain. For ICON an on the fly extension of the grid is not possible, leading to missing data at the boundaries. Therefore the namelist-switch max_missing defines the treshold for the allowed fraction of missingness. Altough the topographical corrected radiation can be calculated for both ICON and COSMO grids, the two sets of fields cannot be considered as identical, because for ICON grids one assumes plain (non-tilted) grid-cells, whereas for COSMO one also takes into account self-shading and effects related to tilted-plains for the skyview-factor.</p> <p>The number of horizons is specified in the namelist. For the COSMO-7 and COSMO-2 setup 24 horizons are recommended. The icon-only parameter radius defines the radial distance taken into account for the topographical corrected radiation parameters. To account for the anisotropic behaviour of longwave-radiation, the namelist parameter itype_scaling defines the power of the term SIN(horizon-angle) in the equation of the skyview-factor. Due to performance reasons, for ICON the parameter min_circ_cov determines how many grid-cells can be skipped on the circumference considered for the computations.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#raw-topography-data","title":"Raw topography data","text":"<p>The namelist <code>INPUT_ORO</code> gives the possibility to switch between two raw orographical data sets (GLOBE, ASTER, or MERIT/REMA). In contrast to the 90m-data of MERIT/REMA, it must be considered, that the 30m-data of ASTER are not completely downloaded and are therefore not globally available. The downloaded region extends from 60N to 60S and from 180W to 180E. It is not recommended to derive the topographical parameters from ASTER if the region is beyond 60 degrees north or south. The ASTER files are arranged as displayed in Figure 2. As the computational time of the program extpar_topo_to_buffer depends mainly on the number of ASTER files that are read in, two new parameters are introduced in the namelist. These two parameters give the number of columns and rows of the used ASTER files. The filenames of the desired ASTER files must be given manually. Figure 2 gives an example on how to use these parameters in the case of COSMO-2. A similar approach is used for MERIT/REMA DEM as shown in Figure 3. The latitude range between 60-90 deg S is covered by REMA DEM, which was mapped to the MERIT data format by BKG, Germany. If GLOBE is used the columns and rows are set to 4 and all GLOBE files must be listed in the topo_files parameter. A check in the program extpar_topo_to_buffer is introduced, which gives a warning if the borders of the domain are exceeded. This is followed by an abortion of this program. As there is no need to calculate the subgrid scale parameters (SSO) for high resolution setups, there is the logical switch lsso_parm to turn off the calculation of the SSOs.</p> <p></p> <p> Figure 2: Illustration of the single domains of the 240 ASTER tiles. An example of how the three parameters ntiles_columns, ntiles_row and topo_files in the namelist could look like is given in red. </p> <p></p> <p> Figure 3: Illustration of the single domains of the 60 MERIT and the 12 REMA tiles below 60 deg S latitude. </p> <p>Furthermore the variables of the namelist <code>INPUT_ORO</code>, which cover all the raw topographical data information, are fed into the program. In this namelist the path of the raw data is given as well as the names of the topography data files. An integer switch allows the choice between the highly resolved, non-global topography ASTER, the global but coarser MERIT/REMA and the coarser and global data set GLOBE (1: GLOBE, 2: ASTER, 3: MERIT/REMA). Furthermore the logical switch to decide whether the SSO parameters are desired or not is read. In order to define the right number of raw data tiles the variables ntiles_column and ntiles_row must be available in the namelist. Additionally, the names for the buffer and output files are defined.</p> <p>The topography data files must be manually changed in the run script, when switching from GLOBE to ASTER, or MERIT/REMA and vice versa.</p> <p>Then, the number of tiles of the raw topography data is defined (this varies between the raw data sets: 16 tiles for GLOBE, 1 - 240 tiles for ASTER, 72 tiles for MERIT/REMA). This value is the product of the number of tiles in each column and each row. The variables concerning the raw topography are allocated and in a further step filled with the according values. These values are the edges of each raw topography tile, the number of gridpoints in x- and y-direction, as well as the resolution in both directions. These are directly deduced from the raw data NetCDF files. Finally the borders of the ASTER domain are defined, when ASTER is used.</p> <p>After the definition of the target grid and the topography set, a check examines the compatibility of the user specified input with the target grid; as ASTER is not globally available at the moment it is checked that the user specified domain is contained in the current ASTER domain. And, if this is not the case, the extpar_topo_to_buffer is aborted with an error message.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#scale-separation-input","title":"Scale separation input","text":"<p>The namelist <code>INPUT_SCALE_SEP</code> gives all the information needed to calculate the SSO parameters and roughness length based on a 3 km filtered topography. Thus the logical switch <code>lscale_separation</code> must be read to decide if a scale separation is desired or not. Furthermore the raw data files and path must be provided. Note that the <code>lscale_separation</code> can only be set to .TRUE. if GLOBE is used as topography, as there is no ASTER or MERIT/REMA based 3 km filtered topography available yet. Additionally the user must decide if the computation of the SSO parameters make sense or not.  Table 3 can give some assistance to come to the right decision.</p> <p></p> Resolution Calculation of standard deviation <code>lscale_separation</code> Model resolution is smaller than raw data resolution SSOs: \\(\\sigma = 0\\),z0: \\(\\hspace{12pt}\\sigma = 0\\) .FALSE. Model resolution is greater than the raw data resolution but smaller than 3 km SSOs: \\(\\sigma = 0\\),z0: \\(\\hspace{12pt}\\sigma = \\sum {(model - raw\\hspace{2pt} data)}^{2}\\) .FALSE. and lsso_param = .FALSE. Model resolution is greater than 3 km SSOs: \\(\\sigma = \\sum {(model - 3km\\hspace{2pt} filt )}^{2}\\),z0: \\(\\hspace{12pt}\\sigma = \\sum {(3km\\hspace{2pt} filt - raw\\hspace{2pt} data)}^{2}\\) .TRUE. <p> Table 3: Recommendations on the usage of the scale separation. Be aware that the actual model topography resolution is approximately twice as large as the model resolution. E.g. COSMO-2: The resolution of the topography is approximately 4 km. </p>"},{"location":"user_manual/user_manual_03_fortran_modules/#orographical-smoothing-input","title":"Orographical smoothing input","text":"<p>The last namelist that must be read before allocating the orography is the namelist <code>INPUT_OROSMOOTH</code>, which defines all the variables needed to perform an orographical smoothing. The lfilter_oro logical switch, controls the computation of the smoothing in EXTPAR.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#aggregation-of-the-raw-topography-to-the-target-grid","title":"Aggregation of the raw topography to the target grid","text":"<p>The subroutine det_topo_tiles_grid defines the grid of each raw topography data tile. For this, the start and end latitude and longitude of each tile, the distance between two grid points in the latitudinal and longitudinal direction (dlat, dlon) as well as the number of grid points in both directions (nlat, nlon) are derived for each tile. Additionally, the grid for the whole GLOBE, ASTER, or MERIT/REMA domain is derived; This is done in the subroutine det_topo_grid.</p> <p>Before the raw topography can be aggregated on the target grid, the target variables must be allocated. These variables include the land fraction (FR_LAND), the elevation of the surface (hh_target), the standard deviation of the elevation (stdh_topo), the roughness length of the topography (z0_topo), the sub-grid scale orography parameters (theta_topo, aniso_topo and slope_topo) and the topographical corrected radiation parameters (slope_asp, slope_ang, horizon and skyview). For the ICON grid some additional parameters must also be allocated.</p> <p>The following paragraphs describe computations on the raw data grid.</p> <p>The subroutine agg_topo_data_to_target_grid does the actual work of aggregating the raw topography to the target grid. The whole topographical data set is divided in bands of 500 grid points in the latitudinal direction and the whole range of the raw data domain in the longitudinal direction (compare for this the black band in  Fig. 4). This band is introduced to optimize memory usage, as it is not possible to read the whole raw data in one pass. In order to read the correct raw data the start and end index of each tile (green crosses in  Fig. 4) is defined. These indices are additionally associated with a start and end index (red circles in  Fig. 4) inside the band. The definition of the two kinds of indices is performed by the routine get_topo_tile_block_indices. With this band the whole raw data is read step by step as suggested in  Fig. 4. If the scale separation is desired the same procedure is applied to the 3 km filtered topography.</p> <p></p> <p> Figure 4: Schematic illustration of the filling of the raw data with a 500 grid points long band. The green crosses indicate the start end end latitudes and longitudes of each raw topography tile (light blue tiles), whereas the red circles show the indices inside the band, where the green indices of the tiles must be placed. </p> <p>After this step, a temporary variable of elevation values is filled. This variable consists of three rows, which comprises the whole longitude range of the raw topography data. This is used to deduce the gradients of the topography, which are calculated as averaged differences between one eastern and one western grid point (x-gradient) or with one northern and one southern grid point (y-gradient). From these gradients in x- and y- direction also the squared gradients and the dx\\(\\ast\\)dy are computed.</p> <p>This is followed by a call of the subroutine find_rotated_lonlat_grid_element_index. This routine defines to which grid element of the target grid a certain grid element of the raw topography belongs. The allocation of the raw data points to the target grid element is performed as shown in Fig. 5 a). All raw data elements that are closer than half a grid point (green box) to the target point (red circle) are used to define the value at the corresponding target grid point. Only the green grid elements in Fig. 5 b) belong to a target grid element. The rest of the raw topography is unused.</p> <p></p> <p> Figure 5: a) Illustration of the aggregation of the raw data to the target grid. The red circle indicates a target grid point, while the green rectangle represents the part of the raw data that is aggregated on the target grid point. b) Showing the target grid on top of the raw data set, where only the green grid points of the raw data are used for the target grid. </p> <p>The elevations of raw data pixels that belong to one target grid element are summed up, and the number of raw data pixels contributing to one target grid element is tracked. A summation of the raw data values for each target grid element is also performed for the squared elevation, which is later used for the standard deviation, and for the gradients calculated before, which are required for the computation of the subgrid scale orography parameters. The latter is only calculated if the SSO parameters are desired. When making use of the scale separation the squared differences between the original and the 3 km filtered topography must be computed at every grid point. This is needed in order to calculate the roughness length specific standard deviation. After these calculations, the temporary rows are shifted to the north and the computation is repeated for the next center line. As soon as a band of 500 rows is finished a new one will be read in.</p> <p>Now that all auxiliary variables are available, all loops over the raw topography data are closed and a new one over all the grid points of the target grid is opened.</p> <p>The following paragraphs describe computations on the target grid.</p> <p>First of all the elevation is calculated as the mean of all the raw topography data points that are enclosed in one target grid point.</p> <p>As soon as the topography is available on the target grid, the orographical smoothing is applied using the subroutine do_orosmooth.</p> <p>In a next step the variance and the standard deviation of the elevation at each target grid point is estimated. Subsequently, the SSO parameters angle of principle axis, anisotropy factor and slope parameter are calculated according to Lott and Miller (1996). These SSOs are only calculated if the SSO switch is set to .TRUE. and if the standard deviation of the height is more than 10 meters, as the trivial case of the ocean is tried to be avoided. If the scale separation is switched on the SSOs are based on the 3 km filtered topography. Finally the orographical roughness length is calculated using the standard deviation, but only if at least one raw data pixel is present in the target grid element.</p> <p>In the case where no raw topography data pixel is available in a target grid, a weighted bilinear interpolation between neighboring raw data grid element is performed to obtain an elevation in all target grid points. This mainly happens if the raw topography has a similar resolution as the target grid. If the bilinear interpolation needs to be applied, all the SSO as well as z0 are set to zero for this grid element. With this step the end of the subroutine agg_topo_data_to_target_grid is reached.</p> <p>In the program extpar_topo_to_buffer an additional check on SSOs and z0 is performed. If none of the elements of the target grid is associated with at least ten raw data pixels, or as soon as one single element is not associated with any raw data pixel, all the SSOs and z0 are set to zero.</p> <p>As soon as there is a value for all the target grid elements, the calculation for the topographical corrected radiation parameters can start, if desired at all.</p> <p>Finally NetCDF files for the orography based external parameters are created, where different NetCDF routines are used for each grid type, as different parameters are needed for each of them. If the lradtopo is set to .TRUE. the enlarged domain is cut back to the user specified domain, before writing it to the NetCDF file.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#used-namelist-files-and-data-in-output","title":"Used namelist files and data in-/output","text":"<ul> <li> <p>namelist files: INPUT_grid_org, INPUT_COSMO_GRID,     INPUT_ICON_GRID,     INPUT_ORO, INPUT_OROSMOOTH, INPUT_RADTOPO</p> </li> <li> <p>data input (GLOBE): GLOBE_A10.nc - GLOBE_P10.nc</p> </li> <li> <p>data input (ASTER): ASTER_T001.nc - ASTER_T240.nc</p> </li> <li> <p>data input (MERIT/REMA): MERIT_N90-N60_E150-E180.nc4 -     REMA_BKG_S60-S90_W180-W150.nc4</p> </li> <li> <p>data input (filtered): GLOBE_A_filt_lanczos_window.nc -     GLOBE_P_filt_lanczos_window.nc,     GLOBE_A_filt_tukey_0.75_3.0_it4.nc -     GLOBE_P_filt_tukey_0.75_3.0_it4.nc</p> </li> <li> <p>Output: buffer file with orography data (/orography_io_extpar/     orography_buffer_file)     output file with orography data (used in extpar_cru_to_buffer)     (/orography_io_extpar/ orography_output_file)</p> </li> </ul>"},{"location":"user_manual/user_manual_03_fortran_modules/#extpar_landuse_to_buffer","title":"extpar_landuse_to_buffer","text":""},{"location":"user_manual/user_manual_03_fortran_modules/#short-description_1","title":"Short description","text":"<p>The executable extpar_landuse_to_buffer aggregates the land use data to the target grid. Five different raw datasets can be processed: Globcover, GLC2000, GLCC, ESA CCI-LC and Ecoclimap Second Generation (Ecoclimap-SG from here onwards). As GLC2000 and Globcover do not include Antarctica, GLCC or ESA CCI-LC data can be used for the missing areas. The landuse executable also includes the TERRA-URB module, controlled by the logical switch l_terra_urb; see section 3.2.2 for details.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#target-grid-definition_1","title":"Target grid definition","text":"<p>The definition of the target grid is done by reading the namelist <code>INPUT_grid_org</code>. This namelist contains the information about the grid type, which can either be ICON or COSMO. With the information about the grid type, the namelist containing the grid definition can be read. The name of the namelist must be changed manually by the user, according to the chosen grid type. The namelist must either be <code>INPUT_ICON</code> or <code>INPUT_COSMO</code>. For a more exact description of the target grid definition, read the subsection 'Target grid definition' in section 3.1. After specifying the grid definition the southern band of the target grid is defined. This information is important, as the two raw data sets GLC2000 and Globcover do not cover the region below 60 degrees south. If this region is desired by the user, the third data set must be considered for the domain below the southern band. Additionally the target fields for the land use data are allocated.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#raw-landuse-data","title":"Raw landuse data","text":"<p>In a next step the namelist <code>INPUT_LU</code> is read. It contains an integer switch (i_landuse_data) that gives the possibility to choose between the five different raw data sets e.g., 1 (Globcover), 2 (GLC2000), 3 (GLCC), 5 (ESA CCI-LC), and 6 (Ecoclimap-SG). For Globcover one can additionally choose to use the corine landuse dataset by setting the logical switch (l_use_corine) to TRUE. Furthermore the path and the filename of the desired raw data and of GLCC are specified there. The user must adjust the filename and path manually according to the chosen raw data in i_landuse_data. In addition the name of the desired lookup table is read, which again can be chosen by the user using an integer switch ilookup_table_lu. The lookup tables are described in more detail in Table 5. The names of the buffer files for the target landuse fields and for the target GLCC fields are also specified in this namelist. Finally, the aforementioned l_terra_urb logical switch can be specified (the default value is .FALSE.).</p> <p>After having read the namelists, the number of tiles of the raw data set is defined. The number of tiles is set to 1 as default and must only be changed for the raw data set Globcover or ESA CCI-LC, which are composed of 6 tiles. The basic information of the Globcover tiles, such as the latitude and longitude edges and the resolution is allocated according to the number of tiles. Later these variables are filled with the respective information, read from the NetCDF files directly.</p> <p>For the remaining procedures the three different raw land use data have their separate routines, which are constructed identically.</p> <p>The allocation of the data is done using the number of grid points in the latitudinal and longitudinal direction. Furthermore the land-use target fields are allocated using the target grid for the dimension size and the number of land-use classes. The land-use classes differ for the three raw data sets and are described in more detail in Table 4.</p> <p></p> Data Set Number of Class Name of Class (Total number of Classes) GLOBCOVER (23) 01 irrigated croplands 02 rainfed croplands 03 mosaic cropland (50-70%) - vegetation (20-50%) 04 mosaic vegetation (50-70%) - cropland (20-50%) 05 closed broadleaved evergreen forest 06 closed broadleaved deciduous forest 07 open broadleaved deciduous forest 08 closed needleleaved evergreen forest 09 open needleleaved decid. or evergr. forest 10 mixed broadleaved and needleleaved forest 11 mosaic shrubland (50-70%) - grassland (20-50%) 12 mosaic grassland (50-70%) - shrubland (20-50%) 13 closed to open shrubland 14 closed to open herbaceous vegetation 15 sparse vegetation 16 closed to open forest regulary flooded 17 closed forest or shrubland permanently flooded 18 closed to open grassland regularly flooded 19 artificial surfaces 20 bare areas 21 water bodies 22 permanent snow and ice 23 undefined Corine (23) Corine (23) (CLC: 2.1.2, 2.1.3) 11 irrigated croplands (CLC: 2.1.1) 14 rainfed croplands (CLC: 2.4.2, 2.4.3) 20 mosaic cropland (50-70%) - vegetation (20-50%) (CLC: 2.4.4) 30 mosaic vegetation (50-70%) - cropland (20-50%) 40 closed broadleaved evergreen forest (CLC: 3.1.1) 50 closed broadleaved deciduous forest 60 open broadleaved deciduous forest (CLC: 3.1.2) 70 closed needleleaved evergreen forest (CLC: 1.4.1) 90 open needleleaved decid. or evergr. forest (CLC: 3.1.3) 100 mixed broadleaved and needleleaved forest (CLC: 2.2.3, 3.2.4) 110 mosaic shrubland (50-70%) - grassland (20-50%) (CLC: 2.2.2, 3.2.2) 120 mosaic grassland (50-70%) - shrubland (20-50%) (CLC: 2.2.1) 130 closed to open shrubland (CLC: 2.3.1, 3.2.3) 140 closed to open herbaceous vegetation (CLC: 3.2.1) 150 sparse vegetation 160 closed to open forest regulary flooded (CLC: 4.1.2) 170 closed forest or shrubland permanently flooded (CLC: 4.1.1) 180 closed to open grassland regularly flooded (CLC: 1.1.1, 1.1.2, 1.2.1, 1.2.2, 1.2.3, 1.2.4, 1.3.3, 1.4.2) 190 artificial surfaces (CLC: 3.3.1, 3.3.2, 3.3.3, 3.3.4, 1.3.1, 1.3.2) 200 bare areas (CLC: 4.2.1, 4.2.2, 4.2.3, 5.1.1, 5.1.2, 5.2.1, 5.2.2, 5.2.3) 210 water bodies (CLC: 3.3.5) 220 permanent snow and ice (CLC: 9.9.9) 230 undefined GLC2000 (23) 01 evergreen broadleaf tree 02 deciduous broadleaf tree closed 03 deciduous broadleaf tree open 04 evergreen needleleaf tree 05 deciduous needleleaf tree 06 mixed leaf tree 07 fresh water flooded tree 08 saline water flooded tree 09 mosaic tree / other natural vegetation 10 burnt tree cover 11 evergreen shrubs closed-open 12 deciduous shrubs closed-open 13 herbaceous cover closed-open 14 sparse herbaceous or grass 15 flooded shrub or herbaceous 16 cultivated and managed areas 17 mosaic crop/tree/natural vegetation 18 mosaic crop/shrub or grass 19 bare areas 20 water bodies 21 snow and ice 22 artificial surfaces 23 undefined GLCC (24) 01 urban and built-up land 02 dryland cropland and pasture 03 irrigated cropland and pasture 04 mixed dryland/irrigated 05 cropland/grassland mosaic 06 cropland/woodland mosaic 07 grassland 08 shrubland 09 mixed shrubland/grassland 10 savanna 11 decidous broadleaf forest 12 decidous needleleaf forest 13 evergreen broadleaf forest 14 evergreen needleleaf forest 15 mixed forest 16 water bodies 17 herbaceous wetland 18 wooded wetland 19 barren or sparsely vegetated 20 herbaceous tundra 21 wooded tundra 22 mixed tundra 23 bare ground tundra 24 snow or ice Ecoclimap-SG (33) 01 sea and oceans 02 lakes 03 rivers 04 bare land 05 bare rock 06 permanent snow 07 boreal broadleaf deciduous 08 temperate broadleaf deciduous 09 tropical broadleaf deciduous 10 temperate broadleaf evergreen 11 tropical broadleaf evergreen 12 boreal needleleaf evergreen 13 temperate needleleaf evergreen 14 boreal needleleaf deciduous 15 shrubs 16 boreal grassland 17 temperate grassland 18 tropical grassland 19 winter C3 crops (lower T) 20 summer C3 crops 21 C4 crops (warmer environments) 22 flooded trees 23 flooded grassland 24 LCZ1: compact high-rise 25 LCZ2: compact midrise 26 LCZ3: compact low-rise 27 LCZ4: open high-rise 28 LCZ5: open midrise 29 LCZ6: open low-rise 30 LCZ7: lightweight low-rise 31 LCZ8: large low-rise 32 LCZ9: sparsely built 33 LCZ10: heavy industry <p> Table 4: Land-use classes for the different raw data sets. The Corine   LandCover (CLC) classes in the left column indicate how the CLC is   mapped to the corresponding GlobCover class. </p> <p>After the allocation of the data a check is performed to query, if the user desires a domain that goes beyond the southern bound of the raw data. If it is the case, the GLCC target fields are allocated as well.</p> <p>In case that Globcover is used, the grid for the single tiles must be defined as well.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#aggregation-of-the-raw-land-use-data-to-the-target-field","title":"Aggregation of the raw land-use data to the target field","text":"<p>The definition and allocation part is done and the most important part, the aggregation of the raw data to the target grid can be performed. In order to be able to aggregate the data, the lookup table must first be initialized. The initial values differ for the various settings listed in Table 5. Also the name of the lookup table must be defined using the integer numbers specified in the namelist <code>INPUT_LU</code>. The integer number are listed together with their associated lookup table names in Table 5.</p> <p> Raw Data Integer Setting Name of the lookup table GLOBCOVER 1 operational settings Asensio, 2011 2 experimental settings, analog to lookup tables of ECOCLIMAP Asensio, 2010 GLC2000 1 operational settings of GME Ritter, 2007 2 operational settings of COSMO Heise, 2005 3 experimental settings, analog to lookup tables of ECOCLIMAP Asensio, 2010 GLCC 1 operational settings of GME Ritter, 2007 2 operational settings of COSMO Heise, 2005 3 experimental settings, analog to lookup tables of ECOCLIMAP Asensio, 2010 ESA CCI-LC 1 experimental settings Helmert, 2019 Ecoclimap-SG 1 Globcover analogue with added LCZs from Oke <p>Table 5: Names of the lookup tables and the different possible settings for each raw land-use data set. </p> <p>The following paragraphs describe computations on the raw data grid.</p> <p>For GLC2000 and GLCC, the raw data is read in lines of a complete longitude going from 180 degrees east to 180 degrees west, through a loop over the latitude. Before any calculation is performed, it is tested if the value of the latitude is contained inside the targed domain. In case it is not, the loop is cycled. Reading of the data line-wise can be done from the NetCDF file directly.</p> <p>Using the routine find_nearest_target_grid_element each raw data pixel is assigned to a target grid point. A more precise description and a figure that describes the procedure can be found in paragraph 'Aggregation of the raw topography to the target grid' and in Fig. 5 in section 3.1.</p> <p>As Globcover and ESA CCI-LC are composed of six tiles, the reading of the raw data must be performed in a different way than for the other three data sets. The reading of the data for Globcover is done in the same way as for the topography. Compare the paragraph 'Aggregation of the raw topography to the target grid' in section 3.1. As there is no need to calculate gradients for the land use, the corresponding variable, which contains three lines of raw data, is not used.</p> <p>The lookup table is then fed with the land use class, which gives a value for all the target fields listed in Table 6.</p> <p> Variable long name Variable short name Fraction Land FR_LAND Ice fraction FR_ICE Plant cover maximum PLCOV_MX Plant cover minimum PLCOV_MN Leaf area index maximum LAI_MX Leaf area index minimum LAI_MN Minimal stomata resistance RS_MIN Urban area fraction URBAN Fraction of deciduous forest FOR_D Fraction of evergreen forest FOR_E Longwave surface emissivity EMISS_RAD Root depth ROOTDP Roughness length Z0 <p>Table 6: The variables that are computed using the raw land-use data. </p> <p>The number of grid points that fall into the same target grid and land use class are summed up. The values of the target fields are weighted with the whole pixel area and summed up. Except for the emissivity, which is the only land-use parameter that also has valid values over water, only land pixels are considered. Values that depend on the plant cover, such as PLCOV_MX, PLCOV_MN, LAI_MN, LAI_MX, RS_MIN, FOR_E, FOR_D, ROOTDP and z0, are weighted with the plant cover maximum in addition to the pixel area.</p> <p>The following paragraphs describe computations on the target grid.</p> <p>The total area and the land area of each target grid point is first defined. Then the weighted sums of the target fields derived in the previous step are normalized to obtain the definite values. The emissivity and the number of land use classes are normalized by the total area to obtain the correct emissivity and area fraction of each land use class. The other parameters are only considered if the area_land is larger than zero: FR_LAND and FR_ICE are normalized with the total area, URBAN, FOR_D, FOR_E, PLCOV_MN and PLCOV_MX are normalized by the land area, the ROOTDP, LAI_MN, LAI_MX and RS_MIN are normalized by the area covered by plants. If only sea pixels are found, all the fields are undefined.</p> <p>Finally land-use classes are defined for target grid points that do not contain any raw data pixel. In contrary to the topography, where a bilinear interpolation is performed, here the nearest neighbor is searched. The associated land use class is used with the lookup tables, and the target fields are defined.</p> <p>The target fields are written to a NetCDF buffer file, which can later be used for the consistency check. There is a file for the chosen land use data set, and one, if needed at all, for the GLCC land use data. Finally the allocated memory is deallocated again.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#terra_urb","title":"TERRA-URB","text":"<p>NOTE: currently the TERRA-URB module in EXTPAR only works with the Ecoclimap-SG database, as this is the only database available for extpar with an LCZ map.</p> <p>The executable extpar_landuse_to_buffer also includes the TERRA-URB module, controlled by the logical switch l_terra_urb. This module uses a 2D map of local climate zones (LCZ) to determine a set of urban canopy variables used by TERRA-URB in COSMO/ICON, see  Table 7. The module aggregates the variables and outputs them to the lu_buffer_file. The aggregation procedure follows that of the other land use variables described in the previous sections. The TERRA-URB related variables then pass through the subprogram extpar_consistency_check (see section 3.7) and are written out to the final extpar file for both COSMO and ICON. ICON would typically ignore these fiels and just use the information from the LU_CLASS_FRACION field, as is done for other land use variables, except for when ntiles=1 in which case it needs the 2D fields. The ISA and AHF EXTPAR modules must be turned off when running with l_terra_urb=.true, as these fields are computed within the TERRA-URB module. The code for this module is based upon Matthias Demuzere's WUDAPT-to-COSMO  [@Varentsov2020] and Handrik Wouters' SURY  [@Wouters2016] codes. The LCZ look-up tables are based on the values published in [@Stewart2012; @Stewart2014].</p> <p> Variable name Description FR_URBAN Urban area fraction ISA Impervious surface area AHF Anthropogenic heat flux FR_PAVED Fraction of impervious surface area URB_FR_BLD Urban building fraction URB_H_BLD Urban building height URB_H2W Urban canyon height to width ratio URB_ALB_SO Urban shortwave (solar) albedo URB_ALB_TH Urban thermal albedo URB_EMIS Urban emissivity URB_HCON Urban mean heat conductivity URB_HCAP Urban mean heat capacity <p>Table 7: Varialbes provided by the TERRA-URB module </p>"},{"location":"user_manual/user_manual_03_fortran_modules/#used-namelist-files-and-data-in-output_1","title":"Used namelist files and data in-/output","text":"<ul> <li> <p>namelists files:</p> <ul> <li>INPUT_grid_org</li> <li>INPUT_COSMO_GRID</li> <li>INPUT_ICON_GRID</li> <li>INPUT_LU</li> </ul> </li> <li> <p>data input:</p> <ul> <li>GLC2000_byte.nc, GLCC_usgs_class_byte.nc</li> <li>CORINE_globcover.nc</li> <li>GLOBCOVER_0_16bit.nc - GLOBCOVER_5_16bit.nc</li> <li>ECCI_300m_0.nc - ECCI_300m_5.nc</li> <li>ECOCLIMAP_SG.nc</li> </ul> </li> <li> <p>Output:</p> <ul> <li>buffer file with landuse data (/lu_io_extpar/ lu_buffer_file)</li> <li>buffer file with GLCC data (/glcc_io_extpar/ glcc_buffer_file)</li> </ul> </li> </ul>"},{"location":"user_manual/user_manual_03_fortran_modules/#extpar_aot_to_buffer","title":"extpar_aot_to_buffer","text":""},{"location":"user_manual/user_manual_03_fortran_modules/#short-description_2","title":"Short description","text":"<p>The executable extpar_aot_to_buffer aggregates aerosol optical thickness data to the target grid.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#target-grid-definition_2","title":"Target grid definition","text":"<p>The definition of the target grid is again done using the namelist <code>INPUT_grid_org</code>. As the subroutines are exactly the same as the ones used in extpar_topo_to_buffer, it is referred to the subsection 'Target grid definition' in section 3.1, where the procedure is explained in more detail.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#raw-aerosol-optical-depth-data","title":"Raw aerosol optical depth data","text":"<p>The namelist <code>INPUT_AOT</code> is kept very simple. It contains only the path and the name of the raw aerosol optical depth data. The integer switch (iaot_type) informs EXTPAR which of the 4 available datasets has been chosen: 1 (Tegen), 2 (AeroCom), 3 (MACC-II), 4 (MACv2) or 5 (CAMS) . Additionally, also the filenames of the buffer and output files for the aggregated data is specified.</p> <p>In order to allocate the variables used to read the raw data, the dimensions of the raw data is defined. These dimensions include the number of rows and columns of the NetCDF raw data file, the number of months, which is equal to 12, as a full yearly cycle is described, and the number of types of aerosols contained in the raw data file. This number is 5 for iaot_type=1,2 or 3 , as the raw data file contains the aerosol optical thickness information of black carbon, dust, organic matter, sulfate and sea salt. iaot_type=4 is used for a new formulation of the radiation-aerosol interaction available only in version of COSMO later than 5.04. This provides data of the aerosol optical thickness, the single scattering albedo and the asymmetry factor for the 8 spectral bands defined in the RG92 radiation scheme. iaot_type=5 is used only for ICON model. The raw data file contains the layer-integrated mass information of 11 types of aerosols: Sea Salt (3 bin), Mineral Dust (3 bin), hydrophilic and hydrophobic organic matter, hydrophilic and hydrophobic black carbon and sulfate. Also the raw data file contains the pressure for 60 vertical levels. The 3 first data-sets which provide raw data for different aerosol types refer to Tegen<sup>1</sup>, AeroCom<sup>2</sup> and MACC-II<sup>3</sup> whereas the fourth data-set is derived from MACv2<sup>4</sup> and the fifth data-set is derived from CAMS<sup>5</sup>.</p> <p>In a next step, the complete raw data is read into memory; this is possible since the aerosol optical depth raw data is of rather coarse resolution (see Table 8). Also, the grid of the raw data is determined from NetCDF meta data. Before the aggregation to the target grid can start, the target grid fields must be allocated, using the target grid, the number of months and aerosol types or spectral bands.</p> <p> Raw data set resolution Tegen 4 x 5 degree AeroCom 1 x 1 degree MACC-II 1.125 x 1.125 degree MACv2 1 x 1 degree CAMS 3 x 3 degree x 60 levels <p>Table 8: Resolution of raw data-sets for aerosol optical depths. </p>"},{"location":"user_manual/user_manual_03_fortran_modules/#aggregation-of-the-aerosol-optical-depth-to-the-target-field","title":"Aggregation of the aerosol optical depth to the target field","text":"<p>As the resolution of all raw data sets is so coarse, there is no need to go through the whole raw data set and find the corresponding target grid element. Here there is only one loop over the target grid. For every target grid element four surrounding raw data points are searched for. With these four points, a weight for the bilinear interpolation is computed. As the raw data grids of the 5 different aerosols are equal, the four surrounding points are the same for all months and aerosol types. Four new arrays (SW, SE, NE, NW) are then defined, which contain the four neighbor values, for each month and each type. These can now be used, together with the previously calculated weights, to calculate the bilinear interpolation.</p> <p>Finally the data is saved in a NetCDF buffer and an output file, and the allocated variables are deallocated.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#used-namelist-files-and-data-in-output_2","title":"Used namelist files and data in-/output","text":"<ul> <li> <p>namelists files: INPUT_grid_org, INPUT_COSMO_GRID,     INPUT_ICON_GRID, INPUT_AOT</p> </li> <li> <p>data input: aot_GACP.nc, aod_AeroCom1.nc,     aod_MACC_2003-2012.nc,     aod_MACC_2003-2012_proc.nc, aot_MACv2.nc,     aot_CAMS_2003-2013.nc</p> </li> <li> <p>Output: buffer file with aerosol data (/aerosol_io_extpar/     aot_buffer_file)</p> </li> </ul>"},{"location":"user_manual/user_manual_03_fortran_modules/#extpar_soil_to_buffer","title":"extpar_soil_to_buffer","text":""},{"location":"user_manual/user_manual_03_fortran_modules/#short-description_3","title":"Short description","text":"<p>The executable extpar_soil_to_buffer aggregates soil data of the FAO Digital Soil Map of the World or of the Harmonized World Soil Data (HWSD) to the target grid.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#target-grid-definition_3","title":"Target grid definition","text":"<p>The definition of the target grid is again done using the namelist <code>INPUT_grid_org</code>. As the subroutines are exactly the same as the ones used in extpar_topo_to_buffer, it is referred to the subsection 'Target grid definition' in section 3.1, where the procedure is explained in more detail.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#raw-soil-data","title":"Raw soil data","text":"<p>The variables for the raw soil data are read from the namelist <code>INPUT_SOIL</code>. These variables are the path and the names of the raw data files and two switches to decide whether the FAO or the HWSD data should be used and if the deep soil data is desired or not. The integer switch isoil_data determines the raw data and processing used: 1 for FAO, 2 for the HWSD data-set<sup>6</sup> and 3 for the use of HWSD data with mapping to TERRA soil types. The switch to choose the production of deep soil information is a logical (only applicable to isoil_data=2). Additionally, the names of the buffer files are specified. Be aware that a change of the integer switch from FAO to HWSD requires also the manual replacement of the raw data file names in the namelist.</p> <p>After reading the namelist, a check is made on the production of subsoil characteristics. This is only supported for HWSD data, and a warning is issued in case of bad usage.</p> <p>The dimensions of the raw soil data are defined, which include the number of grid points in the latitudinal and longitudinal direction, as well as the number of soil data code of the raw data. These values are needed to allocate the soil data with the proper size.</p> <p>The mapping between raw data sets specific codes and some standard soil types is defined; this concerns the soil types <code>undefined</code>, <code>default</code>, <code>ice</code> and <code>water</code>.</p> <p>As the soil data is provided in one single file, all data can be read in one shot. The data that are read from the NetCDF file are the texture and the slope of the soil data and the soil code. The aggregation of the data is done in a different way for the FAO and HWSD data, as these result in two completely different variables. Moreover, for HWSD data, to conserve memory, the topsoil data are allocated first and aggregated to the target grid, before the same is done for the subsoil.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#aggregation-of-the-fao-and-hwsd-data-with-terra-mapping-to-the-target-grid","title":"Aggregation of the FAO and HWSD data with TERRA mapping to the target grid","text":"<p>The following paragraphs describe computations on the raw data grid.</p> <p>The soil data is read using a loop over the latitude and the longitude. This results in a point-wise reading of the raw data. As soon as the point is read, its corresponding target grid element is defined. If the regular latitude/longitude grid point is not contained in the target grid, a new point is read. If however the point is inside the target grid, the aggregation can begin.</p> <p>The number of raw data pixels is increased by one, if a raw data point can be assigned to a target grid point. This number is later used to define the fraction land defined by the soil data. The corresponding soil unit is deduced from the raw data. If the soil unit is zero, this is an ocean pixel and the number of sea points is increased by one. If the soil code differs from zero, the number of land points is increased by one. The soil code is then associated to either a special or a normal soiltype. For all the special soiltypes such as ice, rock, salt, histosols, dunes and no data flags the respective texture (coarse, medium, fine) are defined using a lookup table. All other soil units are described using the texture available in the raw data. These values define the final texture variable <code>texture</code>.</p> <p>The following paragraphs describe computations on the target grid.</p> <p>In the following a loop is opened over the target grid points. First of all the fraction land is defined using the number of land pixels minus the number of inland water pixels, which is then averaged by the number of raw data pixels that were available for the target grid element. In a next step the texture for every target grid element is defined. For the special soiltypes (texture larger than 900) the corresponding number is associated. For the normal soiltypes (texture smaller than 900) the texture is calculated as average of the summed up texture. The resulting texture value is multiplied by 100 and converted into an integer number. This number is used to associate the final soiltype to every target grid element. The soiltypes are described in more detail in table 9. For target grid points that do not contain any raw data points, the nearest neighbor in the raw data is defined. If the target grid point is outside the raw data grid the slope is defined as zero and the texture as undefined.</p> <p> TERRA Code Soiltype raw data code 1 ice and glacier<sup>7</sup> 9001 2 rock, lithosols 9002 3 sand 9003 (salt), 9005 (shifting sands and dunes) and coarse texture 4 sandy loam coarse to medium texture 5 loam (default soiltype) 9009 (undefined), 9012 (dominant part undefined), medium texture 6 loamy clay medium to fine texture 7 clay fine texture 8 histosols (peat) 9004 9 water 9000 (undefined: inland water), -9 (undefined: ocean) <p>Table 9: TERRA soiltypes and their respective FAO raw data codes. </p>"},{"location":"user_manual/user_manual_03_fortran_modules/#aggregation-of-the-hwsd-data-to-the-target-grid","title":"Aggregation of the HWSD data to the target grid","text":"<p>The aggregation starts again with a loop over the latitudes and longitudes. For each grid point a target grid element is looked for. If there is a target grid element, the aggregation can start. The soiltype is defined using the raw data value, if it is above zero, and zero otherwise. Additionally, all the ocean, land and lake points are counted in order to determine the land fraction which is calculated as the difference between the summed up land and lake points normalized by the number of raw data pixels available. For target grid points with no raw data, the nearest neighbor in the raw data is defined.</p> <p>The resulting soiltype is not yet usable, as it contains numbers coded in a world code and not in TERRA soiltypes. This transformation is done in the consistency check, where the special soiltypes of the HWSD data, specified in Table 10, are packed in the variable <code>SOILTYP</code> the normal soiltypes are given in fractions of sand, silt, clay and organic carbon, and the bulk density is also given.</p> <p> TERRA Code Soiltype TERRA Code Soiltype 1 ice and glacier 8 histosols (peat) 2 rock, lithosols 9 water 3 sand 10 alkali flat 4 sandy loam 11 shifting sand, dunes 5 loam (default soiltype) 12 Urban, human disturbed 6 loamy clay 225 Unknown 7 clay <p>Table 10: New TERRA soiltypes deduced from the HWSD data. </p>"},{"location":"user_manual/user_manual_03_fortran_modules/#output-of-the-soil-data","title":"Output of the soil data","text":"<p>The soiltypes and the fraction land, together with the undefined value, the latitudes and longitudes are saved in a NetCDF buffer file. This is later used to perform the consistency check, which is especially important for the HWSD data, as the main transformation of the data takes place there.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#used-namelist-files-and-data-in-output_3","title":"Used namelist files and data in-/output","text":"<ul> <li> <p>namelists files: INPUT_grid_org, INPUT_COSMO_GRID,     INPUT_ICON_GRID, INPUT_SOIL</p> </li> <li> <p>data input: FAO_DSMW_double.nc, FAO_DSMW_float.nc,     HWSD0_30_topsoil.nc, HWSD30_100_subsoil.nc</p> </li> <li> <p>Lookup tables for HWSD: LU_TAB_HWSD_UF.data,     HWSD_DATA_COSMO.data,     HWSD_DATA_COSMO_S.data</p> </li> <li> <p>Output: buffer file with soil data (/soil_io_extpar/     soil_buffer_file)</p> </li> </ul>"},{"location":"user_manual/user_manual_03_fortran_modules/#extpar_flake_to_buffer","title":"extpar_flake_to_buffer","text":""},{"location":"user_manual/user_manual_03_fortran_modules/#short-description_4","title":"Short description","text":"<p>The executable extpar_flake_to_buffer aggregates lake depth data and lake fraction to the target grid.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#target-grid-definition_4","title":"Target grid definition","text":"<p>The definition of the target grid is again done using the namelist <code>INPUT_grid_org</code>. As the subroutines are exactly the same as the ones used in extpar_topo_to_buffer, it is referred to the subsection 'Target grid definition' in section 3.1, where the procedure is explained in more detail.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#raw-lake-data","title":"Raw lake data","text":"<p>As only the target grid dimensions are needed to allocate the target fields, this is done right after the definition of the target grid. Then the namelist <code>INPUT_FLAKE</code> is read to define the path and the filename of the raw lake data. Also the names of the buffer and the output file for the consistency check are given. Once more the dimensions of the raw data are needed to allocate the raw data correctly; these dimensions are deduced from the netcdf file directly and the raw data grid is defined.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#aggregation-of-the-lake-data-to-the-target-grid","title":"Aggregation of the lake data to the target grid","text":"<p>The following paragraphs describe computations on the raw data grid.</p> <p>The data is read row-wise, through a loop over the latitudes, shipping all latitudes not inside the user specified domain. If a row is kept, a new loop over the longitudes is started to treat the raw data point-wise. For each point, the corresponding target field element is defined. This is done in the same way described in the subsection 'Aggregation of the topography to the target grid' in section 3.1 and Fig. 5. The number of raw data pixels that contribute to the target grid value are summed up as well as the lake depth, which is multiplied by a scale factor deduced from the area of each pixel that contributes to a lake fraction.</p> <p>The following paragraphs describe computations on the raw data grid.</p> <p>The lake fraction is derived and the lake depth is obtained by normalizing the weighted sum previously computed. Where no lake depth is available the value is set to undefined (-1). In case that no raw data pixel is available the nearest neighbor in the raw data is searched for.</p> <p>The target fields are then written to a netcdf buffer and output file. Finally the allocated memory can be released.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#used-namelist-files-and-data-in-output_4","title":"Used namelist files and data in-/output","text":"<ul> <li> <p>namelists files: INPUT_grid_org, INPUT_COSMO_GRID,     INPUT_ICON_GRID, INPUT_FLAKE</p> </li> <li> <p>data input: GLDB_lakedepth.nc</p> </li> <li> <p>Output: buffer file with flake data (/flake_io_extpar/     flake_buffer_file)</p> </li> </ul>"},{"location":"user_manual/user_manual_03_fortran_modules/#extpar_hwsdART_to_buffer","title":"extpar_hwsdART_to_buffer","text":""},{"location":"user_manual/user_manual_03_fortran_modules/#short-description_5","title":"Short description","text":"<p>This program processes HWSD (Harmonized World Soil Database) data and aggregates it onto a target grid.</p> <p>The code is a module named \"mo_agg_hwsdART\" that contains a subroutine called \"agg_hwsdART_data_to_target_grid\". This subroutine is used to aggregate data from the HWSD dataset to a target grid. The HWSD dataset contains soil unit information classified according to the USDA soil classification system.</p> <p>The module uses several other modules, including \"mo_logging\" for logging purposes, \"mo_kind\" to define kind parameters, \"mo_hwsdART_data\" to define the different soil types according to the USDA classification, \"mo_hwsdART_tg_fields\" to define variables related to the target grid, and \"mo_grid_structures\" to define grid structures.</p> <p>The subroutine takes input parameters including the target grid structure (\"tg\"), the HWSDART soil unit data (\"hwsdART_soil_unit\"), the grid of HWSDART data (\"hwsdART_grid\"), and the longitude and latitude coordinates of the HWSDART grid (\"lon_hwsdART\" and \"lat_hwsdART\").</p> <p>The subroutine initializes local variables and arrays to store the counts of different soil types in each grid element of the target grid. It also sets an undefined integer value and initializes the count of raw data pixels to zero.</p> <p>The subroutine then iterates over the HWSDART grid and finds the nearest target grid element for each raw data pixel using the \"find_nearest_target_grid_element\" function. If the raw data pixel is out of the range of the target domain, it is skipped.</p> <p>For each valid raw data pixel, the subroutine counts the number of raw data pixels in the target grid element and increments the count for the corresponding soil type in the local arrays.</p> <p>After the iteration over the HWSDART grid, the subroutine iterates over the target grid to calculate the fraction of each soil type in each grid element. It divides the count of each soil type by the total number of raw data pixels in the grid element and stores the fractions in the corresponding variables.</p> <p>The code aggregates the HWSD soil data in USDA scheme to a target grid, calculating the fraction of each soil type in each grid element for application in ICON-ART simulations.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#used-namelist-files-and-data-in-output_5","title":"Used namelist files and data in-/output","text":"<ul> <li> <p>namelists files: INPUT_grid_org, INPUT_ICON_GRID, INPUT_hwsdART</p> </li> <li> <p>data input: HWSD0_USDA.nc</p> </li> <li> <p>Output: buffer file with fraction of soil type classes     (hwsdART_extpar_ICON.nc)</p> </li> </ul>"},{"location":"user_manual/user_manual_03_fortran_modules/#extpar_consistency_check","title":"extpar_consistency_check","text":""},{"location":"user_manual/user_manual_03_fortran_modules/#short-description_6","title":"Short description","text":"<p>The extpar_consistency_check is performed after all raw data have been aggregated to the target grid to remove any inconsistencies that may appear among the different data and to derive additional information using multiple raw data sources.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#reading-of-namelists","title":"Reading of namelists","text":"<p>Before the grid is defined, the namelists <code>INPUT_RADTOPO</code>, <code>INPUT_ORO</code> and <code>INPUT_SOIL</code> are read to obtain the settings of the different switches that are used (e.g. lradtopo, itopo_type, lsso_param, isoil_data, ldeep_soil). Then the namelist <code>INPUT_grid_org</code> is read to obtain the target grid information and the grid type.</p> <p>In a next step the <code>INPUT_LU</code> is read by extpar_consistency_check to check if the GLCC data set is required, which is the case if the target grid domain reaches more to the south than the chosen raw land-use data set. (Globcover and GLC_2000 are not global.)</p> <p>If the namelist INPUT_ERA is present (indicating that one uses the ERA climatologies generated by extpar_era_to_buffer) the buffer file name is retrieved. If this namelist is not present (legacy climatologies from ICON-REMAP-TOOL are used), the buffer file names in INPUT_CHECK are read. After that step, all other namelists of the EXTPAR modules are read in order to retrieve the buffer file name for each data set. These files are read and all the variables needed for the final external parameters file are allocated.</p> <p>An additional namelist that is used is <code>INPUT_CHECK</code>, it contains a couple of switches to define the processing in the consistency check.</p> <p>The first task after reading the namelists is to derive the correct land sea mask from the land use data. If the GLCC data must be used, the land sea mask below the southern band is deduced from GLCC.</p> <p>Then the total roughness length is computed as the sum of the roughness length deduced from the land-use and the topography.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#consistency-check-for-water-and-ice-pixels","title":"Consistency check for water and ice pixels","text":"<p>The definition of a water grid element is based on the land-use data. The vegetation is set to zero for all water grid elements and FAO derived soil type is set to water. For non water pixels with undefined or invalid soil type, the FAO derived soil type is either set to default, which is loam, or to ice for regions that are below 60 degrees south (where only Antarctica is located).</p> <p>All the points that are classified as ice in the land-use data but not in the FAO derived soil type, are changed to ice in the latter; the vegetation of these pixels is set to zero.</p> <p>The HWSD derived soiltype needs a transformation from the world code to the TERRA code, which is performed here. The world code is decoded with the TERRA HWSD lookup table, to define the regions that contain a special soiltype (see the special soiltypes in Table 10). For each grid point the world code is associated to the single fractions of the soil composition, using an other lookup table. If there is a point that does not contain a bulk density it is calculated using the formula of the cultivated topsoil or the compact subsoil from Hollisa et al. (2012)<sup>8</sup> and Woesten et al. (1999)<sup>9</sup>. Furthermore there is a special treatment of peat with histosols. The whole procedure is also done for the subsoil, if it is desired at all.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#consistency-check-of-lake-data","title":"Consistency check of lake data","text":"<p>Water grid points are either declared as lake or ocean, thus over land a fraction lake and over the ocean a fraction ocean is defined. Where the fraction land deduced from the topography is smaller than 0.99 the fraction ocean is defined. All the other points are used to determine the fraction lake. Both fractions are defined such that fr_lake or fr_ocean plus fr_land_lu (fraction land deduced from land-use) sum up to one. Some smaller seas must be defined manually, thus for the region of the Dead Sea and the Caspian Sea not fraction lake but fraction ocean is calculated.</p> <p>For fr_land <sup>10</sup> and fr_ocean <sup>11</sup> larger than a half, the lake depth is set to undefined. A default value for the lake depth is used for grid elements with a lake fraction <sup>12</sup> larger than a half and a negative lake depth. Additionally a maximum and minimum lake depth is defined. Included is also a manual correction of the depth of Lake Constance.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#consistency-check-of-albedo-data","title":"Consistency check of albedo data","text":"<p>The consistency check of the albedo data concerns land pixels that have a albedo smaller than 0.07. For these pixels a weighted bilinear interpolation is performed. Only land points are used for the interpolation, if there is no surrounding land point a warning message is printed. Values that are still too small receive a soiltype dependent albedo. This is done for all three wavelengths.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#consistency-check-of-ndvi-data","title":"Consistency check of NDVI data","text":"<p>The next consistency check is performed with the normalized difference vegetation index (NDVI). The NDVI values are set to undefined for water grid points. Additionally, values that are smaller than a predefined value are set to exactly this value.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#consistency-check-of-the-temperature-climatology","title":"Consistency check of the temperature climatology","text":"<p>The consistency check of the temperature climatology contains a height correction and is only performed for the finer resolved temperature climatology (e.g. it_cl_type = 1). The temperature is set to undefined for all the sea points. For land points that have a valid temperature, it is adjusted to the height. This is done by considering a constant temperature rate of 0.65 K per 100m:</p> <p>\\(\\frac{dT}{dh} = -\\frac{0.65 K}{100 m}\\).</p> <p>Target points that do not contain temperature values larger than zero are filled with surrounding values. First a valid point is looked for in the surrounding \\(3\\times3\\) grid box. If still no valid point can be found, it is searched along the longitude, and if nothing else helps the nearest neighbor is tried.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#consistency-check-of-all-other-fields","title":"Consistency check of all other fields","text":"<p>All other fields are assumed to be independent and are written to the output file exactly as they were read in. A special treatment applies to the ISA, AHF, EMISS and S_ORO fields. Whenever their respective namelist input file is missing in the working directory where extpar_consistency_check is executed these fields are not added to the output file. An exception to this rule applies to the ISA and AHF fields which are added to the output file if the logical switch l_terra_urb is set to .TRUE. in the INPUT_LU namelist; see section 3.2.2 for more details.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#definition-of-special-points","title":"Definition of special points","text":"<p>Be aware that the definition of special points has only been tested for the COSMO grid and can only be used if the FAO raw soil type is used. At the moment there are three special points (1: Falkenberg, 2: Waldstation, 3: Lindenberg). At each of these points, values for soiltype_sp, z0_sp, rootdp_sp, plcovmn_sp, plcovmx_sp, laimn_sp, laimx_sp can be explicitly set by the user. The coordinates of the special point are also user specified. If no special treatment at these points is desired the number_special_points must be set to zero (see Table 11). If no special treatment is desired at all, the integer switch i_lsm_treatment can be set to 1 instead of 2.</p> <p> number_special_points Treatment of special points 0 NO treatment of special points 1 special treatment of Falkenberg 2 special treatment of Falkenberg and Waldstation 3 special treatment of Falkenberg, Waldstation and Lindenberg <p>Table 11: Usage of the namelist parameter number_special_points. </p>"},{"location":"user_manual/user_manual_03_fortran_modules/#reduced-main-memory-usage","title":"Reduced main memory usage","text":"<p>Since Exptar Version 5.4 a new feature was introduced which allows the running of extpar_consistency_check for very high resolution global grids without any restrictions on the hardware memory specifications. A POSIX mmap based implemetation of disk caching arrays is used to use main memory as much as possible and, if more memory is required, the duty to handle this request is delegated to the kernel. A requirement to run this properly is the provision of swap space in the expected total memory use. With this technique we could process a global R2B11 ICON grid (around 1.25 km grid resolution) on a server with 256 GB main memory. Of course processing gets quite slow, but is still in the order of a couple of cups of coffee.</p> <p>The feature can be enabled with the namelist variable l_use_array_cache = .TRUE. in namelist extpar_consistency_check_io. The namelist variable default is l_use_array_cache =.FALSE., which is selecting the standard heap allocation by Fortran's ALLOCATE statement.</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#writing-output","title":"Writing output","text":"<p>The final results are written into a netcdf file. The output file name can be specified in the namelist <code>INPUT_CHECK</code>.</p> <p>Since EXTPAR Version 5.4 the output possibilities have been extended for ICON only. The EXTPAR output procedure for COSMO did not change with Version 5.4. As ICON and a lot of its associated tools (eg. CDO, DWD icontools) are already using a single abstract interfacing library CDI, a re-implementation for the final EXTPAR output procedure with CDI to prepare for future developments is provided. Note, that this re-implementation replaces the former writing-routine completely. For a detailed description of CDI look at  https://code.mpimet.mpg.de/projects/cdi .</p>"},{"location":"user_manual/user_manual_03_fortran_modules/#used-namelist-files-and-data-in-output_6","title":"Used namelist files and data in-/output","text":"<ul> <li> <p>namelists files: INPUT_grid_org, INPUT_COSMO_GRID,     INPUT_ICON_GRID, INPUT_CHECK, INPUT_</p> </li> <li> <p>data input: all buffer files from the EXTPAR modules defined in the     <code>INPUT_</code> namelist files</p> </li> <li> <p>data output: netCDF containing all external parameters     (/extpar_consistency_check_io/ netcdf_output_filename)</p> </li> </ul> <ol> <li> <p>Tegen, I., P. Hollrigl, M. Chin, I. Fung, D. Jacob, and J. Penner 1997. Contribution of different aerosol species to the global aerosol extinction optical thickness: Estimates from model results. J. Geophys. Res., 102, 23895-23915.\u00a0\u21a9</p> </li> <li> <p>Kinne, S., M. Schulz, C. Textor, S. Guibert, Y. Balkanski, S.E. Bauer, T. Berntsen, T.F. Berglen, O. Boucher, M. Chin, W. Collins, F. Dentener, T. Diehl, R. Easter, J. Feichter, D. Fillmore, S. Ghan, P. Ginoux, S. Gong, A. Grini, J. Hendricks, M. Herzog, L. Horowitz, I. Isaksen, T. Iversen, A. Kirkev\u00e5g, S. Kloster, D. Koch, J.E. Kristjansson, M. Krol, A. Lauer, J.F. Lamarque, G. Lesins, X. Liu, U. Lohmann, V. Montanaro, G. Myhre, J. Penner, G. Pitari, S. Reddy, \u00d8. Seland, P. Stier, T. Takemura, and X. Tie: An AeroCom initial assessment optical properties in aerosol component modules of global models, Atmos. Chem. Phys., 6, 1815-1834, 2006.\u00a0\u21a9</p> </li> <li> <p>Morcrette, J.-J., O. Boucher, L. Jones, D. Salmond, P. Bechtold, A. Beljaars, A. Benedetti, A. Bonet, J. W. Kaiser, M. Razinger, M. Schulz, S. Serrar, A. J. Simmons, M. Sofiev, M. Suttie, A. M. Tompkins, and A. Untch, 2009: Aerosol analysis and forecast in the ECMWF Integrated Forecast System. Part I: Forward modelling, J. Geophys. Res., 114D, D06206,doi:10.1029/2008JD011235\u00a0\u21a9</p> </li> <li> <p>Kinne, S., D. O'Donnel, P. Stier, S. Kloster, K. Zhang, H. Schmidt, S. Rast, M. Giorgetta, T. F. Eck, and B. Stevens (2013), MAC-v1: A new global aerosol climatology for climate studies, J. Adv. Model. Earth Syst., 5, 704--740, doi:10.1002/jame.20035.\u00a0\u21a9</p> </li> <li> <p>Bozzo, A., Benedetti, A., Flemming, J., Kipling, Z., R\u00e9my, S. (2020). An aerosol climatology for global models based on the tropospheric aerosol scheme in the Integrated Forecasting System of ECMWF. Geoscientific Model Development, 13(3), 1007-1034.\u00a0\u21a9</p> </li> <li> <p>Release 5.0 of COSMO and 2.0 of INT2LM do not support HWSD data, as the representation of the soil associated with this new data set has changed and is based on the use of pedotransfer functions and on fraction of soil components (e.g. clay, silt, ...)\u00a0\u21a9</p> </li> <li> <p>Soiltypes written in bold indicate a special soiltype.\u00a0\u21a9</p> </li> <li> <p>J.M. Hollisa, J. Hannamb and P.H. Bellamyb, February 2012, Empirically-derived pedotransfer functions for predicting bulk density in European soils, European Journal of Soil Science, 63, 96109 doi: 10.1111/j.1365-2389.2011.01412.x\u00a0\u21a9</p> </li> <li> <p>J.H.M. Woesten, A. Lilly, A. Nemes and C. Le Bas, Development and use of a database of hydraulic properties of European soils, Geoderma, Volume 90, Issues 34, July 1999, Pages 169-185, doi: 10.1016/S0016-7061(98)00132-3.\u00a0\u21a9</p> </li> <li> <p>derived from the land use data\u00a0\u21a9</p> </li> <li> <p>derived from the land use data\u00a0\u21a9</p> </li> <li> <p>derived from the lake data set\u00a0\u21a9</p> </li> </ol>"},{"location":"user_manual/user_manual_04_python_modules/","title":"Python Modules","text":""},{"location":"user_manual/user_manual_04_python_modules/#General","title":"General Workflow","text":"<p>The general workflow of all Python modules is the same. An exemplary workflow of the Python modules is described below:</p> <p>At the beginning of the program information about the environment on which EXTPAR is running is written to the logfile and all left-overs from prior executions of the same EXTPAR module are deleted. In a next step each parameter from the namelist <code>namelist.py</code> is checked for correctness as well as assigned to an internal variable for later use in the program. The specifaction about the target grid is directly read from the Fortan namelist-files <code>INPUT_grid_org</code>. The next step in the modules involves the generation of all necessary meta-data for the buffer files and the write of a namelist files in the style of a Fortran namelist, containing all information needed for the consistency_check at the end. In case of a COSMO target grid, a grid specification file is written, that is later used by CDO for the interpolation.</p> <p>After this is all setup, the most compute-intensive parts like the remapping to the target grid or data modifications are done using CDO. The Python program launches a subshell executing the CDO in it. The output from CDO is reshaped in order to fit the dimensions of the buffer files. After the reshape, the fields and its corresponding metadata is written to a netCDF buffer file. The last step of the programme again deletes all intermediate netCDF or other files written during runtime, that do not serve any purpose.</p> <p>Module-specific modifications or additional computations are described in the paragraph Data processing of each Python module.</p>"},{"location":"user_manual/user_manual_04_python_modules/#namelist","title":"Namelist","text":"<p>The namelist <code>namelist.py</code> contains the Python dictionaries <code>input_alb</code>, <code>input_tclim</code>, <code>input_emiss</code>, <code>input_ndvi</code>, <code>input_ahf</code>, <code>input_isa</code> and <code>input_edgar</code>. These dictionaries replace their corresponding Fortran namelist files <code>INPUT_</code>.</p> <p><code>input_alb</code> provides information about the albedo data type and the paths and filenames of the input/output data.</p> <p><code>input_tclim</code> contains a switch to determine the type of data (coarse or fine) as well as the paths and filenames of the input/output data.</p> <p><code>input_emiss</code> contains a switch to determine the type of emissivity data (full range or long-wave) and the filename and paths of the input/output data.</p> <p><code>input_ndvi</code> only provides information about the the path and the filenames of the input/output data.</p> <p><code>input_era</code> only provides information about the the path and the filenames of the input/output data.</p> <p><code>input_isa</code> contains a switch determine the type of ISA data and provides information about the the path and the filenames of the input/output data.</p> <p><code>input_ahf</code> contains a switch determine the type of AHF data and provides information about the the path and the filenames of the input/output data.</p> <p><code>input_edgar</code> only provides information about the the path and the filenames of the input/output data.</p>"},{"location":"user_manual/user_manual_04_python_modules/#extpar_alb_to_buffer","title":"extpar_alb_to_buffer","text":""},{"location":"user_manual/user_manual_04_python_modules/#short-description-of-the-subprogram-extpar_alb_to_buffer","title":"Short description of the subprogram extpar_alb_to_buffer","text":"<p>The executable extpar_alb_to_buffer allows the aggregation of two different kinds of albedo data to the target grid. The first kind is a climatology of monthly values of total albedo derived from MODIS satellite data for the 3 spectral bands visible, near infrared and ultraviolet. The second kind contains information for soil albedo only in dry and saturated conditions. It originates from the Community Land Model<sup>1</sup>.</p>"},{"location":"user_manual/user_manual_04_python_modules/#data-processing","title":"Data processing","text":"<p>The data is remapped to the target grid using the distance-weighted average interpolation. CDO first generates the weights for the interpolation from one of the input files and then applies these weights to all input files. After the interpolation took place, all values in the range of -100000 - 0.02 are set to 0.02 to prevent unrealistic data-points. All other steps in extpar_alb_to_buffer are following the general workflow of the Python scrips.</p>"},{"location":"user_manual/user_manual_04_python_modules/#used-namelist-files-and-data-in-output","title":"Used namelist files and data in-/output","text":"<ul> <li> <p>namelist files: namelist.py (dict: input_alb), INPUT_grid_org,     INPUT_COSMO_GRID,     INPUT_ICON_GRID</p> </li> <li> <p>generate namelist: INPUT_ALB</p> </li> <li> <p>data input: month_alb.nc, month_alnid.nc, month_aluvd.nc,     global_soil_albedo.nc</p> </li> <li> <p>data output: buffer file with albedo data (input_alb:     alb_buffer_file)</p> </li> </ul>"},{"location":"user_manual/user_manual_04_python_modules/#extpar_cru_to_buffer","title":"extpar_cru_to_buffer","text":""},{"location":"user_manual/user_manual_04_python_modules/#short-description-of-the-subprogram-extpar_cru_to_buffer","title":"Short description of the subprogram extpar_cru_to_buffer","text":"<p>The executable extpar_cru_to_buffer aggregates the temperature climatology of the Climate Research Unit (CRU) to the target grid. The namelist <code>namelist.py</code> gives the information of the path and the name of the raw temperature climatology data file. Additionally, the filename for the buffer is provided. There is an integer switch (it_cl_type), which allows the choice between a newer higher resolved data set for land surfaces only (1) and an older coarser raw data set for sea surfaces in combination with the higher resolved data set over land (2). Aggregation of the coarse data set over land surfaces is no longer supported since EXTPAR Version 5.4.</p>"},{"location":"user_manual/user_manual_04_python_modules/#data-processing_1","title":"Data processing","text":"<p>The data processing with CDO for it_cl_type = 1 involves 4 steps:</p> <ol> <li> <p>Set seapoints in the data to missing value.</p> </li> <li> <p>Extract the fields <code>HSURF</code> from the fine data set.</p> </li> <li> <p>Merge the fields from step 1 and step 2.</p> </li> <li> <p>Remap data from step 3 to the target grid using distance-weighted     average interpolation.</p> </li> </ol> <p>The data processing with CDO for it_cl_type = 2 involves 5 steps:</p> <ol> <li> <p>Convert coarse data from Celsius to Kelvin, calculate yearly mean     values and remap coarse data to the grid of the higher resolved data     set.</p> </li> <li> <p>Take landpoints from the fine data set and the seapoints from the     data processed in step 1.</p> </li> <li> <p>Extract surface height from the buffer file of     extpar_topo_to_buffer</p> </li> <li> <p>Smooth data processed in step 2 and remap to target grid using     distance-weighted average interpolation.</p> </li> <li> <p>Correct data processed in step 4 with the surface height extracted     in step 3.</p> </li> </ol> <p>All subsequent processing on the data follows the general workflow of the Python scripts.</p>"},{"location":"user_manual/user_manual_04_python_modules/#used-namelist-files-and-data-in-output_1","title":"Used namelist files and data in-/output:","text":"<ul> <li> <p>namelists files: namelist.py (dict: input_tclim), INPUT_grid_org,     INPUT_COSMO_GRID,     INPUT_ICON_GRID</p> </li> <li> <p>generate namelist: INPUT_TCLIM</p> </li> <li> <p>data input: absolute_hadcrut3.nc, CRU_T2M_SURF_clim.nc,     CRU_T_SOIL_clim.nc,     orography_buffer_file (it_cl_type = 2 only)</p> </li> <li> <p>Output: buffer file with CRU data (input_tclim:     t_clim_buffer_file)</p> </li> </ul>"},{"location":"user_manual/user_manual_04_python_modules/#extpar_emiss_to_buffer","title":"extpar_emiss_to_buffer","text":""},{"location":"user_manual/user_manual_04_python_modules/#short-description-of-the-subprogram-extpar_emiss_to_buffer","title":"Short description of the subprogram extpar_emiss_to_buffer","text":"<p>The executable extpar_emiss_to_buffer aggregates CAMEL (Combined ASTER and MODIS Emissivity for Land) data to the target grid. For the aggregation of the emissivity the namelist <code>namelist.py</code> provides the path and the file name of the input data. The buffer file name is defined as well. There exists the integer switch (iemiss_type) to determine whether one wants to use the broad band emissivity for the 3.6 and 14.3 micron spectral range (1) or the broad band emissivity between 8.0 and 13.5 micron spectral range (2).</p>"},{"location":"user_manual/user_manual_04_python_modules/#data-processing_2","title":"Data processing","text":"<p>After the generation of the interpolation weights artificial low values below 0.5 are set to -999. In a subsequent processing step -999 is set to the value for missing data. In order to not have missing data in the field to interpolate, all missing values are set to the values of its nearest neighbour. The last step involves the first order conservative interpolation to the target grid. After the remapping with CDO two additional fields are computed:</p> <ul> <li> <p>EMISS_MAX, the maximum EMISS value over 12 months</p> </li> <li> <p>EMISS_MRAT, the monthly ratio with respect to the maximum EMISS</p> </li> </ul>"},{"location":"user_manual/user_manual_04_python_modules/#used-namelist-files-and-data-in-output_2","title":"Used namelist files and data in-/output:","text":"<ul> <li> <p>namelists files: namelist.py (dict: input_emiss) INPUT_grid_org,     INPUT_COSMO_GRID,     INPUT_ICON_GRID</p> </li> <li> <p>generate namelist: INPUT_EMISS</p> </li> <li> <p>data input: CAM_bbe_full_2010-2015\u1e45c or CAM_bbe_lw_2010-2015\u1e45c</p> </li> <li> <p>Output: buffer file with CAMEL data (input_emiss:     emiss_buffer_file)</p> </li> </ul>"},{"location":"user_manual/user_manual_04_python_modules/#extpar_ndvi_to_buffer","title":"extpar_ndvi_to_buffer","text":""},{"location":"user_manual/user_manual_04_python_modules/#short-description-of-the-subprogram-extpar_ndvi_to_buffer","title":"Short description of the subprogram extpar_ndvi_to_buffer","text":"<p>The executable extpar_ndvi_to_buffer aggregates NDVI data (Normalized Differential Vegetation Index) to the target grid. The namelist <code>namelist.py</code> only contains the path and the file name of the raw NDVI data. No other parameters can be set.</p> <p>For the aggregation of the normalized differential vegetation index the namelist <code>namelist.py</code> is simple. It contains the path and the filename of the raw data set, as well as the names of the buffer. No other parameters can be set.</p>"},{"location":"user_manual/user_manual_04_python_modules/#data-processing_3","title":"Data processing","text":"<p>The remapping to the target grid uses the first order conservative interpolation. After the remapping with CDO two additional fields are computed:</p> <ul> <li> <p>NDVI_MAX, the maximum NDVI value over 12 months</p> </li> <li> <p>NDVI_MRAT, the monthly ratio with respect to the maximum NDVI</p> </li> </ul>"},{"location":"user_manual/user_manual_04_python_modules/#used-namelist-files-and-data-in-output_3","title":"Used namelist files and data in-/output:","text":"<ul> <li> <p>namelists files: namelist.py (dict: input_ndvi), INPUT_grid_org,     INPUT_COSMO_GRID,     INPUT_ICON_GRID</p> </li> <li> <p>generate namelist: INPUT_NDVI</p> </li> <li> <p>data input: NDVI_1998_2003.nc</p> </li> <li> <p>Output: buffer file with NDVI data (input_ndvi: ndvi_buffer_file)</p> </li> </ul>"},{"location":"user_manual/user_manual_04_python_modules/#extpar_era_to_buffer","title":"extpar_era_to_buffer","text":""},{"location":"user_manual/user_manual_04_python_modules/#short-description-of-the-subprogram-extpar_era_to_buffer","title":"Short description of the subprogram extpar_era_to_buffer","text":"<p>The executable extpar_era_to_buffer aggregates ERA data (T2M, SST, W_SNOW and ORO) to the target grid. It replaces the two NetCDF-Files generated by ICON-REMAP at DWD. Note that this executable is for Icon-grids only.</p> <p>For the aggregation of the ERA climatologies the namelist <code>namelist.py</code> is simple again. It contains the type of ERA climatology (ERA5 (1) or ERA-I (2)) the path and the filenames of the raw data sets, as well as the names of the buffer. No other parameters can be set.</p>"},{"location":"user_manual/user_manual_04_python_modules/#data-processing_4","title":"Data processing","text":"<p>The remapping to the target grid uses the first order conservative interpolation. After the remapping with CDO the field W_SNOW is scaled by a factor 1000. No other processing steps take place.</p>"},{"location":"user_manual/user_manual_04_python_modules/#used-namelist-files-and-data-in-output_4","title":"Used namelist files and data in-/output:","text":"<ul> <li> <p>namelists files: namelist.py (dict: input_era), INPUT_grid_org,     INPUT_COSMO_GRID,     INPUT_ICON_GRID</p> </li> <li> <p>generate namelist: INPUT_ERA</p> </li> <li> <p>data input: ERA5_ORO_1990.nc, ERA5_SD_1990_2019.nc,     ERA5_SST_1990_2019.nc and ERA5_T2M_1990_2019.nc     ERA-I_ORO_1986.nc, ERA-I_SD_1986_2015.nc,     ERA-I_SST_1986_2015.nc and ERA-I_T2M_1986_2015</p> </li> <li> <p>Output: buffer file with ERA data (input_era: era_buffer_file)</p> </li> </ul>"},{"location":"user_manual/user_manual_04_python_modules/#extpar_isa_to_buffer","title":"extpar_isa_to_buffer","text":""},{"location":"user_manual/user_manual_04_python_modules/#short-description-of-the-subprogram-extpar_isa_to_buffer","title":"Short description of the subprogram extpar_isa_to_buffer","text":"<p>The executable extpar_isa_to_buffer allows the aggregation or interpolation of data on the fraction of impervious surface area needed by TERRA_URB to the target grid.</p> <p>For the aggregation of the ISA the namelist <code>namelist.py</code> is simple again. It contains the type of ISA (NOAA (1) or EEA (2)) the path and the filenames of the raw data sets, as well as the names of the buffer. No other parameters can be set. Note that the underlying processing does not differ between different types of ISA</p> <p>The remapping to the target grid uses the bilinear interpolation. No other processing steps take place.</p>"},{"location":"user_manual/user_manual_04_python_modules/#used-namelist-files-and-data-in-output_5","title":"Used namelist files and data in-/output:","text":"<ul> <li> <p>namelists files: namelist.py (dict: input_isa), INPUT_grid_org,     INPUT_COSMO_GRID,     INPUT_ICON_GRID</p> </li> <li> <p>generate namelist: INPUT_ISA</p> </li> <li> <p>data input: EEA_ISA_16bit_lonlat.nc( isa_type=2),     NOAA_ISA_16bit_lonlat.nc (isa_type=1)</p> </li> <li> <p>Output: buffer file with ISA data (input_isa: isa_buffer_file)</p> </li> </ul>"},{"location":"user_manual/user_manual_04_python_modules/#extpar_ahf_to_buffer","title":"extpar_ahf_to_buffer","text":""},{"location":"user_manual/user_manual_04_python_modules/#short-description-of-the-subprogram-extpar_ahf_to_buffer","title":"Short description of the subprogram extpar_ahf_to_buffer","text":"<p>The executable extpar_ahf_to_buffer allows the aggregation or interpolation of data on the anthropogenic heat flux needed by TERRA_URB to the target grid.</p> <p>For the aggregation of the AHF the namelist <code>namelist.py</code> is simple again. It contains the type of AHF (2.5min (1) or 30sec (2)) the path and the filenames of the raw data sets, as well as the names of the buffer. No other parameters can be set. Note that the underlying processing does not differ between different types of AHF</p> <p>The remapping to the target grid uses the bilinear interpolation. No other processing steps take place.</p>"},{"location":"user_manual/user_manual_04_python_modules/#used-namelist-files-and-data-in-output_6","title":"Used namelist files and data in-/output:","text":"<ul> <li> <p>namelists files: namelist.py (dict: input_ahf), INPUT_grid_org,     INPUT_COSMO_GRID,     INPUT_ICON_GRID</p> </li> <li> <p>generate namelist: INPUT_AHF</p> </li> <li> <p>data input: AHF_2006_2.5min_lonlat.nc     (ahf_type=1),AHF_2006_NOAA_30sec_lonlat.nc (ahf_type=2)</p> </li> <li> <p>Output: buffer file with AHF data (input_ahf: ahf_buffer_file)</p> </li> </ul>"},{"location":"user_manual/user_manual_04_python_modules/#extpar_edgar_to_buffer","title":"extpar_edgar_to_buffer","text":""},{"location":"user_manual/user_manual_04_python_modules/#short-description-of-the-subprogram-extpar_edgar_to_buffer","title":"Short description of the subprogram extpar_edgar_to_buffer","text":"<p>The executable extpar_edgar_to_buffer allows the interpolation of global emission data for black carbon, organic carbon and sulfur dioxide needed for the 2D-Aerosol in ICON to the target grid.</p> <p>The namelist contains only the path to the raw data, the raw data file names and the name of the buffer file.</p> <p>The remapping to the target grid uses the first order conservative interpolation. No other processing steps take place.</p>"},{"location":"user_manual/user_manual_04_python_modules/#used-namelist-files-and-data-in-output_7","title":"Used namelist files and data in-/output:","text":"<ul> <li> <p>namelists files: namelist.py (dict: input_edgar), INPUT_grid_org,     INPUT_ICON_GRID</p> </li> <li> <p>generate namelist: INPUT_edgar</p> </li> <li> <p>data input: v8.1_FT2022_AP_NH3_2022_TOTALS_flx.nc,     v8.1_FT2022_AP_OC_2022_TOTALS_flx.nc,     v8.1_FT2022_AP_BC_2022_TOTALS_flx.nc,     v8.1_FT2022_AP_NOx_2022_TOTALS_flx.nc,     v8.1_FT2022_AP_SO2_2022_TOTALS_flx.nc</p> </li> <li> <p>Output: buffer file with EDGAR data (input_edgar:     edgar_buffer_file)</p> </li> </ul>"},{"location":"user_manual/user_manual_04_python_modules/#extpar_cdnc_to_buffer","title":"extpar_cdnc_to_buffer","text":""},{"location":"user_manual/user_manual_04_python_modules/#short-description-of-the-subprogram-extpar_cdnc_to_buffer","title":"Short description of the subprogram extpar_cdnc_to_buffer","text":"<p>The executable extpar_cdnc_to_buffer allows the interpolation of climatology data for cloud droplet number needed for the Cloud-Aerosol in ICON to the target grid.</p> <p>The namelist contains only the path to the raw data, the raw data file names and the name of the buffer file.</p> <p>The remapping to the target grid uses the first order conservative interpolation. No other processing steps take place.</p>"},{"location":"user_manual/user_manual_04_python_modules/#used-namelist-files-and-data-in-output_8","title":"Used namelist files and data in-/output:","text":"<ul> <li> <p>namelists files: namelist.py (dict: input_cdnc), INPUT_grid_org,     INPUT_ICON_GRID</p> </li> <li> <p>generate namelist: INPUT_cdnc</p> </li> <li> <p>data input: cdnc_climatology_Q06.nc</p> </li> <li> <p>Output: buffer file with cloud droplet number data (input_cdnc:     cdnc_buffer_file)</p> </li> </ul> <ol> <li> <p>https://svn-ccsm-inputdata.cgd.ucar.edu/trunk/inputdata/lnd/clm2/rawdata/mksrf_soilcol.081008.nc </p> <p>Lawrence, P. J. and T. N. Chase (2007). \"Representing a new MODIS consistent land surface in the Community Land Model (CLM 3.0).\" Journal of Geophysical Research-Biogeosciences 112(G1).\\ Table 3.3 in: Oleson, K.W., D.M. Lawrence, G.B. Bonan, M.G. Flanner, E. Kluzek, P.J. Lawrence, S. Levis, S.C. Swenson, P.E. Thornton, A. Dai, M. Decker, R. Dickinson, J. Feddema, C.L. Heald, F. Hoffman, J.-F. Lamarque, N. Mahowald, G.-Y. Niu, T. Qian, J. Randerson, S. Running, K. Sakaguchi, A. Slater, R. Stockli, A. Wang, Z.-L. Yang, Xi. Zeng, and Xu. Zeng, 2010: Technical Description of version 4.0 of the Community Land Model (CLM). NCAR Technical Note NCAR/TN-478+STR, National Center for Atmospheric Research, Boulder, CO, 257 pp.\u00a0\u21a9</p> </li> </ol>"},{"location":"user_manual/user_manual_05_current_limitations/","title":"Current Limitations","text":"<p>The EXTPAR software is subject to several limitations:</p> <ul> <li> <p>The ASTER domain can only be used from 60\u00b0N to 60\u00b0S. Be aware that an     additional border of several gridpoints is needed if the     topographically corrected parameters are desired. If the ASTER     domain is exceeded a warning message is printed and the program     extpar_topo_to_buffer is aborted.</p> </li> <li> <p>The ASTER data shows some deficits, which are listed below:</p> <ul> <li> <p>Beyond 60 degrees north and south, the ASTER raw data set     features several areas where no value is available e.g., over     Finland (private communication with HIRLAM).</p> </li> <li> <p>Some bogus regions may appear in complex topography. One of     these regions is located near Grindelwald in Switzerland.</p> </li> <li> <p>The ASTER data are subject to artefacts of the satellite     fly-over bands. Discontinuities can be spotted at the borders of     such bands. In high latitudes these bands are better visible     than in the low latitudes.</p> </li> <li> <p>As the correction of these deficits are time consuming no effort     has been expended to remove these.</p> </li> <li> <p>The ASTER data might be subject to a shift of a half gridpoint     (15 meters) in both directions.</p> </li> </ul> </li> <li> <p>There is no 3 km filtered ASTER or MERIT/REMA data set to derive the     subgrid scale orography (<code>SSO</code>) parameters and the roughness length     (<code>z0</code>) for ASTER.</p> </li> <li> <p>The HWSD raw data is in a test phase. Furthermore a new version of     Int2lm and TERRA is needed to make use of these data sets.</p> </li> <li> <p>The subsoil can only be used if the HWSD data is used for the     topsoil. If the FAO and the HWSD data are combined a warning message     is printed and the <code>ldeep_soil parameter</code> is set to <code>.FALSE.</code>.</p> </li> <li> <p>The special points are only tested for the COSMO grid. Also it is     not possible to use these corrections if the soil raw data set is     HWSD.</p> </li> <li> <p>Array-caching in the consistency_check is only supported for GCC     compiler.</p> </li> <li> <p>CAMS aersosl data <code>iaot_type = 5</code> is only supported for Intel compiler.</p> </li> </ul>"},{"location":"user_manual/user_manual_06_namelist_input/","title":"Namelist Input","text":"<p>EXTPAR uses 3 types of namelists in order to determine in which way data is processed.</p> <ul> <li>Fortran namelists (<code>INPUT_</code>)</li> <li>Python dictionaries (<code>input_in namelist.py</code>)</li> <li>Fortran namelists written by Python scripts</li> </ul> <p>Whereas for the Fortran namelists and the Python dictionaries the user can specify parameters and filenames, the Fortran namelists generated during runtime by the Python scripts do not allow any user interaction.</p>"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_namelist_files","title":"Namelist files","text":"Namelist file Purpose Made by script Used by program INPUT_grid_org define target grid type runscript <code>extpar_consistency_check</code>, <code>extpar_aot_to_buffer</code>, <code>extpar_landuse_to_buffer</code>, <code>extpar_topo_to_buffer</code>, <code>extpar_cru_to_buffer</code>, <code>extpar_ndvi_to_buffer</code>, <code>extpar_soil_to_buffer</code>, <code>extpar_flake_to_buffer</code>, <code>extpar_isa_to_buffer</code>, <code>extpar_ahf_to_buffer</code>, <code>extpar_emiss_to_buffer</code>, <code>extpar_hwsdART_to_buffer</code> INPUT_COSMO_GRID define target domain for COSMO grid runscript <code>extpar_consistency_check</code>, <code>extpar_aot_to_buffer</code>, <code>extpar_landuse_to_buffer</code>, <code>extpar_topo_to_buffer</code>, <code>extpar_cru_to_buffer</code>, <code>extpar_ndvi_to_buffer</code>, <code>extpar_soil_to_buffer</code>, <code>extpar_flake_to_buffer</code>, <code>extpar_isa_to_buffer</code>, <code>extpar_ahf_to_buffer</code>, <code>extpar_emiss_to_buffer</code>, <code>extpar_hwsdART_to_buffer</code> INPUT_ICON_GRID define target domain for ICON grid runscript <code>extpar_consistency_check</code>, <code>extpar_aot_to_buffer</code>, <code>extpar_landuse_to_buffer</code>, <code>extpar_topo_to_buffer</code>, <code>extpar_cru_to_buffer</code>, <code>extpar_ndvi_to_buffer</code>, <code>extpar_soil_to_buffer</code>, <code>extpar_flake_to_buffer</code>, <code>extpar_isa_to_buffer</code>, <code>extpar_ahf_to_buffer</code>, <code>extpar_emiss_to_buffer</code> INPUT_ORO settings for orography data runscript <code>extpar_topo_to_buffer</code> INPUT_OROSMOOTH settings for orography smoothing runscript <code>extpar_topo_to_buffer</code> INPUT_RADTOPO settings for generating topographical shading fields runscript <code>extpar_topo_to_buffer</code> INPUT_SCALE_SEP settings to control scale separation for SSO an Z0 calculation runscript <code>extpar_topo_to_buffer</code> INPUT_LU settings for landuse data runscript <code>extpar_landuse_to_buffer</code> INPUT_AOT settings for aerosol data runscript <code>extpar_aot_to_buffer</code> INPUT_TCLIM settings for temperature data <code>extpar_cru_to_buffer</code> <code>extpar_consistency_check</code> INPUT_NDVI settings for NDVI data <code>extpar_ndvi_to_buffer</code> <code>extpar_consistency_check</code> INPUT_SOIL settings for soil data runscript <code>extpar_soil_to_buffer</code> INPUT_FLAKE settings for lake data runscript <code>extpar_flake_to_buffer</code> INPUT_ALB settings for albedo data <code>extpar_albedo_to_buffer</code> <code>extpar_consistency_check</code> INPUT_ISA settings for fraction of impervious surface area data <code>extpar_isa_to_buffer</code> <code>extpar_consistency_check</code> INPUT_AHF settings for anthropogenic heat flux data <code>extpar_ahf_to_buffer</code> <code>extpar_consistency_check</code> INPUT_EMISS settings for emissivity data <code>extpar_emiss_to_buffer</code> <code>extpar_consistency_check</code> INPUT_hwsdART settings for HWSD USDA data <code>extpar_hwsdART_to_buffer</code> INPUT_edgar settings for EDGAR data <code>extpar_edgar_to_buffer</code> <code>extpar_consistency_check</code> INPUT_CDNC settings for cdnc data <code>extpar_cdnc_to_buffer</code> <code>extpar_consistency_check</code> INPUT_ERA settings for ERA data <code>extpar_era_to_buffer</code> <code>extpar_consistency_check</code> INPUT_CHECK settings for the consistency check runscript <code>extpar_consistency_check</code>"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_grid_def","title":"Grid Definition","text":"<p>The specification of the model type (COSMO or ICON) is done in the namelist file INPUT_grid_org, the detailed target grid description for the model domain has to be provided in the namelists files INPUT_COSMO_GRID or INPUT_ICON_GRID.</p>"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_grid_def_general","title":"General","text":""},{"location":"user_manual/user_manual_06_namelist_input/#namelist-grid_def-input_grid_org","title":"NAMELIST /grid_def/ (INPUT_grid_org)","text":"<p>The namelist /grid_def/ defines the target grid type and the filenames with the namelists of the detailed target grid definition.</p> Parameter Type Default Unit Description igrid_type integer target grid type, 1 for ICON, 2 for COSMO domain_def_namelist character namelist file with domain definition domain_refinement character namelist file with domain refinement definition (e.g. for the ICON grid)"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_grid_def_icon","title":"ICON","text":""},{"location":"user_manual/user_manual_06_namelist_input/#namelist-icon_grid_info-input_icon_grid","title":"NAMELIST /icon_grid_info/ (INPUT_ICON_GRID)","text":"<p>The namelist /icon_grid_info/ specifies the filenames and the directory of the Icon grid files with the coordinates of the Icon grid.</p> Parameter Type Default Unit Description icon_grid_dir character path to directory which contains the ICON grid file with the coordinates icon_grid_nc_file character (max_dom) filename of the ICON grid file with the coordinates"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_grid_def_cosmo","title":"COSMO","text":""},{"location":"user_manual/user_manual_06_namelist_input/#namelist-lmgrid-input_cosmo_grid","title":"NAMELIST /lmgrid/ (INPUT_COSMO_GRID)","text":"<p>The COSMO grid is defined by a rotated latlon-grid.</p> Parameter Type Default Unit Description pollon real -170. deg longitude of the rotated north pole (in degrees, \\(E&gt;0\\)) pollat real 32.5 deg latitude of the rotated north pole (in degrees, \\(N&gt;0\\)) polgam real 0. deg longitude (in the rotated system) of the geographical north pole dlon real 0.08 deg grid point distance in zonal direction (in degrees) dlat real 0.08 deg grid point distance in meridional direction (in degrees) startlon_tot real -1.252 deg transformed longitude of the lower left grid point of the total domain (in degrees, \\(E&gt;0\\)) startlat_tot real -7.972 deg transformed latitude of the lower left grid point of the total domain (in degrees, \\(N&gt;0\\)) ie_tot integer 51 number of grid points in zonal direction je_tot integer 51 number of grid points in meridional direction ke_tot integer 0 number of grid points in vertical direction"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_orography","title":"Orography","text":""},{"location":"user_manual/user_manual_06_namelist_input/#namelist-oro_runcontrol-input_oro","title":"NAMELIST /oro_runcontrol/ (INPUT_ORO)","text":"Parameter Type Default Unit Description lcompute_sgsl logical .false. switch to activate subgrid-slope calculation"},{"location":"user_manual/user_manual_06_namelist_input/#namelist-orography_raw_data-input_oro","title":"NAMELIST /orography_raw_data/ (INPUT_ORO)","text":"Parameter Type Default Unit Description itopo_type integer switch to choose an orography raw data set; 1 GLOBE, 2 ASTER, 3 MERIT/REMA lsso_param logical switch to choose if SSO parameters should be generated or not raw_data_orography_path character path to orography raw data ntiles_column integer GLOBE: 4 ASTER, MERIT/REMA: x number of tile columns of desired region ntiles_row integer GLOBE: 4 ASTER, MERIT/REMA: x number of tile rows of desired region topo_files character filenames of GLOBE (16 tiles) / ASTER (240 tiles)/ MERIT/REMA (72 tiles) raw data sets lsubtract_mean_slope logical .FALSE. for operational NWP-ICON treatment of mean slope in computation of SSO parameters for ICON"},{"location":"user_manual/user_manual_06_namelist_input/#namelist-orography_io_extpar-input_oro","title":"NAMELIST /orography_io_extpar/ (INPUT_ORO)","text":"Parameter Type Default Unit Description orography_buffer_file character name for orography buffer file orography_output_file character name for orography output file"},{"location":"user_manual/user_manual_06_namelist_input/#namelist-sgsl_io_extpar-input_oro","title":"NAMELIST /sgsl_io_extpar/ (INPUT_ORO)","text":"Parameter Type Default Unit Description lpreproc_oro logical .false. read S_ORO from existing NetCDF (.false.) or preprocess from raw topography datasets (.true.) sgsl_files character filenames of raw data tiles to be used S_ORO_A10 to S_ORO_P10 (GLOBE) or S_ORO_T001 to S_ORO_T240"},{"location":"user_manual/user_manual_06_namelist_input/#namelist-orography_smoothing-input_orosmooth","title":"NAMELIST /orography_smoothing/ (INPUT_OROSMOOTH)","text":"Parameter Type Default Unit Description lfilter_oro logical FALSE Cosmo-only: switch for orogaphy smoothing ilow_pass_oro integer 0 type of orogaphy smoothing and stencil width numfilt_oro integer 1 number of filter applications eps_filter real 10 smoothing parameter (\"strength\" of the filtering) ifill_valley integer 1 fill valleys before or after oro smoothing (1: before, 2: after) rfill_valley real 0 m mask for valley filling (threshold value) ilow_pass_xso integer 1 type of orogaphy eXtra SmOothing and stencil width (for steep orography) numfilt_xso integer 1 number of applications of the eXtra filter lxso_first logical FALSE eXtra SmOothing before or after orography smoothing (TRUE/FALSE) rxso_mask real 0 m mask for eXtra SmOothing (threshold value)"},{"location":"user_manual/user_manual_06_namelist_input/#namelist-radtopo-input_radtopo","title":"NAMELIST /radtopo/ (INPUT_RADTOPO)","text":"Parameter Type Default Unit Description lradtopo logical Switch for radiation corrected topography parameters. Not recommended to use if orographical smoothing is false and smoothing is performed in Int2lm later, because of resulting inconsistencies. nhori integer 24 Number of horizon angles radius integer 40000 m Icon-only: Radial distance considered for computation of horizon min_circ_cov integer 1 - Icon-only: Number of gridcells to be skipped at circumference of circle. A value of 1 considers all points, whereas a value of 5 only consider every fifth point at the circumference. Note that the effect of this switch is dependent on the resolution of the grid as well on the radius choosen. max_missing real 0.9 - Icon-only: Upper limit for fraction of missingness for the horizon parameter. Grid-cells with values above will be set to 0. itype_scaling integer 2 - Icon-only: Power of the caling factor SIN(horizon-angle) applied to the geometric skyview factor to account for the anisotropic nature of longwave radiation."},{"location":"user_manual/user_manual_06_namelist_input/#namelist-scale_separated_raw_data-input_scale_sep","title":"NAMELIST /scale_separated_raw_data/ (INPUT_SCALE_SEP)","text":"Parameter Type Default Unit Description lscale_separation logical Switch for scale separation. It can only be used in combination with GLOBE as raw data set. raw_data_scale_sep_path character path to 3 km filtered topography scale_sep_files character filename of 3 km filtered topography"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_lu","title":"Land Use Data","text":""},{"location":"user_manual/user_manual_06_namelist_input/#namelist-lu_raw_data-input_lu","title":"NAMELIST <code>/lu_raw_data/</code> (INPUT_LU)","text":"Parameter Type Default Unit Description <code>raw_data_lu_path</code> character path to land use data <code>raw_data_lu_filename</code> character filename of land use raw data <code>i_landuse_data</code> integer switch to choose a land use raw data set: 1 Globcover2009, 2 GLC2000, 3 GLCC, 5 ESA CCI-LC, 6 Ecoclimap-SG <code>l_use_corine</code> logical .false. switch to use Corine land use dataset; only possible if <code>i_landuse_data = 1</code> <code>ilookup_table_lu</code> integer switch to choose a lookup table: - GLC2000 and GLCC: 1: operational settings of GME (Ritter, 2007) 2: operational settings of COSMO (Heise, 2005) 3: experimental setting, analogous to lookup tables of ECOCLIMAP (Asensio 2010) - GLOBCOVER 2009: 1: operational settings (Asensio, 2011) 2: experimental settings, analogous to lookup tables of ECOCLIMAP (Asensio 2010) - ESA CCI-LC: 1: experimental settings (Helmert, 2019) - Ecoclimap-SG: 1: Globcover analogue with added LCZs from Oke <code>ntiles_globcover</code> integer 6 number of tiles for GLOBCOVER data <code>ncolumn_tiles</code> integer number of columns in tile matrix <code>l_terra_urb</code> logical .false. switch to use TERRA-URB (see TERRA-URB); only possible if <code>i_landuse_data = 6</code>"},{"location":"user_manual/user_manual_06_namelist_input/#namelist-glcc_raw_data-input_lu","title":"NAMELIST <code>/glcc_raw_data/</code> (INPUT_LU)","text":"Parameter Type Default Unit Description <code>raw_data_glcc_path</code> character path to GLCC data <code>raw_data_glcc_filename</code> character filename of GLCC raw data <code>ilookup_table_glcc</code> integer switch to choose a lookup table: 1: operational settings of GME (Ritter, 2007) 2: operational settings of COSMO (Heise, 2005) 3: experimental setting, analogous to lookup tables of ECOCLIMAP (Asensio 2010)"},{"location":"user_manual/user_manual_06_namelist_input/#namelist-glcc_io_extpar-input_lu","title":"NAMELIST <code>/glcc_io_extpar/</code> (INPUT_LU)","text":"Parameter Type Default Unit Description <code>glcc_buffer_file</code> character name for GLCC buffer file"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_aot","title":"Aerosol Optical Depth","text":""},{"location":"user_manual/user_manual_06_namelist_input/#namelist-aerosol_raw_data-input_aot","title":"NAMELIST <code>/aerosol_raw_data/</code> (INPUT_AOT)","text":"Parameter Type Default Unit Description <code>raw_data_aot_path</code> character path to aerosol raw data <code>raw_data_aot_filename</code> character filename of aerosol raw data <code>iaot_type</code> integer 1 index to specify AOD raw data set: 1:Tegen, 2:AeroCom, 3:MACC-II, 4:MACv2, 5:CAMS"},{"location":"user_manual/user_manual_06_namelist_input/#namelist-aerosol_io_extpar-input_aot","title":"NAMELIST <code>/aerosol_io_extpar/</code> (INPUT_AOT)","text":"Parameter Type Default Unit Description <code>aot_buffer_file</code> character name for aerosol buffer file"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_cru","title":"Climatological 2m Temperature","text":""},{"location":"user_manual/user_manual_06_namelist_input/#dict-input_tclim-namelistpy","title":"DICT <code>input_tclim</code> (namelist.py)","text":"Parameter Type Default Unit Description <code>raw_data_t_clim_path</code> character path to T2m climatology data <code>raw_data_t_clim_coarse</code> character filename of coarse T2m climatology data <code>raw_data_t_clim_fine</code> character filename of fine T2m climatology data <code>it_cl_type</code> integer switch to choose between the new and fine (1) and the old and coarse over sea and the fine over land (2) raw data set. Note that the fine data set (1) is topographically corrected. <code>t_clim_buffer_file</code> character name for T_clim buffer file"},{"location":"user_manual/user_manual_06_namelist_input/#ndvi-data","title":"NDVI Data","text":""},{"location":"user_manual/user_manual_06_namelist_input/#dict-input_ndvi-namelistpy","title":"DICT <code>input_ndvi</code> (namelist.py)","text":"Parameter Type Default Unit Description <code>raw_data_ndvi_path</code> character Path to NDVI raw data <code>raw_data_ndvi_filename</code> character Filename of NDVI raw data <code>ndvi_buffer_file</code> character Name for NDVI buffer file"},{"location":"user_manual/user_manual_06_namelist_input/#edgar-data","title":"EDGAR Data","text":""},{"location":"user_manual/user_manual_06_namelist_input/#dict-input_edgar-namelistpy","title":"DICT <code>input_edgar</code> (namelist.py)","text":"Parameter Type Default Unit Description <code>raw_data_edgar_path</code> character Path to EDGAR raw data <code>raw_data_edgar_filename_bc</code> character Filename of EDGAR black carbon raw data <code>raw_data_edgar_filename_oc</code> character Filename of EDGAR organic carbon raw data <code>raw_data_edgar_filename_so2</code> character Filename of EDGAR sulfur dioxide raw data <code>raw_data_edgar_filename_nh3</code> character Filename of EDGAR ammonia raw data <code>raw_data_edgar_filename_nox</code> character Filename of EDGAR nitrogen oxides raw data"},{"location":"user_manual/user_manual_06_namelist_input/#cdnc-data","title":"CDNC Data","text":""},{"location":"user_manual/user_manual_06_namelist_input/#dict-input_cdnc-namelistpy","title":"DICT <code>input_cdnc</code> (namelist.py)","text":"Parameter Type Default Unit Description <code>raw_data_cdnc_path</code> character Path to CDNC raw data <code>raw_data_cdnc_filename</code> character Filename of CDNC raw data"},{"location":"user_manual/user_manual_06_namelist_input/#hwsdart-data","title":"hwsdART Data","text":""},{"location":"user_manual/user_manual_06_namelist_input/#namelist-hwsdart_nml-input_hwsdart","title":"NAMELIST <code>/hwsdART_nml/</code> (<code>INPUT_hwsdART</code>)","text":"Parameter Type Default Unit Description <code>raw_data_hwsdART_path</code> character Path to hwsdART raw data <code>raw_data_hwsdART_filename</code> character Filename of hwsdART raw data <code>hwsdART_output_file</code> character Name for hwsdART output file"},{"location":"user_manual/user_manual_06_namelist_input/#soil-data","title":"Soil Data","text":""},{"location":"user_manual/user_manual_06_namelist_input/#namelist-soil_raw_data-input_soil","title":"NAMELIST <code>/soil_raw_data/</code> (<code>INPUT_SOIL</code>)","text":"Parameter Type Default Unit Description <code>isoil_data</code> integer Switch to choose between raw soil data, 1: FAO, 2: HWSD, 3: HWSD with terra mapping <code>ldeep_soil</code> logical Switch for deep soil, set to <code>.TRUE.</code> if using HWSD data <code>raw_data_soil_path</code> character Path to soil raw data <code>raw_data_soil_filename</code> character Filename of soil raw data <code>raw_data_deep_soil_filename</code> character Filename of deep soil raw data"},{"location":"user_manual/user_manual_06_namelist_input/#namelist-soil_io_extpar-input_soil","title":"NAMELIST <code>/soil_io_extpar/</code> (<code>INPUT_SOIL</code>)","text":"Parameter Type Default Unit Description <code>soil_buffer_file</code> character Name for soil buffer file <code>soil_buffer_file_consistent</code> character Name for soil buffer file after consistency check <code>soil_output_file_consistent</code> character Name for soil output file after consistency check"},{"location":"user_manual/user_manual_06_namelist_input/#namelist-hwsd_index_files-input_soil","title":"NAMELIST <code>/HWSD_index_files/</code> (<code>INPUT_SOIL</code>)","text":"Parameter Type Default Unit Description <code>path_HWSD_index_files</code> character Path to HWSD lookup tables <code>lookup_table_HWSD</code> character Lookup table to convert soil type index from global to TERRA soil type <code>HWSD_data</code> character Lookup table for sand, silt, clay, organic carbon, and bulk density (topsoil) <code>HWSD_data_deep</code> character Lookup table for sand, silt, clay, organic carbon, and bulk density (subsoil) <code>HWSD_data_extpar</code> character Parameter for development purposes"},{"location":"user_manual/user_manual_06_namelist_input/#freshwater-lake-data","title":"Freshwater Lake Data","text":""},{"location":"user_manual/user_manual_06_namelist_input/#namelist-flake_raw_data-input_flake","title":"NAMELIST <code>/flake_raw_data/</code> (<code>INPUT_FLAKE</code>)","text":"Parameter Type Default Unit Description <code>raw_data_flake_path</code> character Path to flake raw data <code>raw_data_flake_filename</code> character Filename of flake raw data"},{"location":"user_manual/user_manual_06_namelist_input/#namelist-flake_io_extpar-input_flake","title":"NAMELIST <code>/flake_io_extpar/</code> (<code>INPUT_FLAKE</code>)","text":"Parameter Type Default Unit Description <code>flake_buffer_file</code> character Name for flake buffer file"},{"location":"user_manual/user_manual_06_namelist_input/#albedo-data","title":"Albedo Data","text":""},{"location":"user_manual/user_manual_06_namelist_input/#dict-input_alb-namelistpy","title":"DICT <code>input_alb</code> (namelist.py)","text":"Parameter Type Default Unit Description <code>raw_data_alb_path</code> character Path to raw albedo data <code>raw_data_alb_filename</code> character Filename of raw albedo data <code>raw_data_alnid_filename</code> character Filename of raw NIR-albedo data <code>raw_data_aluvd_filename</code> character Filename of raw UV-albedo data <code>ialb_type</code> integer Switch to indicate albedo type: 1: total albedo, 2: soil albedo, 3: as 1 without NI and UV fields <code>alb_buffer_file</code> character Name for albedo buffer file"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_isa","title":"ISA Data","text":""},{"location":"user_manual/user_manual_06_namelist_input/#dict-input_isa-namelistpy","title":"DICT <code>input_isa</code> (namelist.py)","text":"Parameter Type Default Unit Description <code>raw_data_isa_path</code> character path to ISA raw data <code>raw_data_isa_filename</code> character filename of ISA raw data <code>isa_type</code> integer type of used ISA data source <code>isa_buffer_file</code> character name for ISA buffer file"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_ahf","title":"AHF Data","text":""},{"location":"user_manual/user_manual_06_namelist_input/#dict-input_ahf-namelistpy","title":"DICT <code>input_ahf</code> (namelist.py)","text":"Parameter Type Default Unit Description <code>raw_data_ahf_path</code> character path to AHF raw data <code>raw_data_ahf_filename</code> character filename of AHF raw data <code>iahf_type</code> integer type of used AHF data source <code>ahf_buffer_file</code> character name for AHF buffer file"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_emissivity","title":"Emissivity Parameter","text":""},{"location":"user_manual/user_manual_06_namelist_input/#dict-input_emiss-namelistpy","title":"DICT <code>input_emiss</code> (namelist.py)","text":"Parameter Type Default Unit Description <code>iemiss_type</code> integer switch to choose between full-range (1) and long-wave (2) emissivity data <code>raw_data_emiss_path</code> character path to emissivity parameter raw data <code>raw_data_emiss_filename</code> character filenames of emissivity raw data <code>emiss_buffer_file</code> character name for emissivity parameter buffer file"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_era","title":"ERA Parameter","text":""},{"location":"user_manual/user_manual_06_namelist_input/#dict-input_era-namelistpy","title":"DICT <code>input_era</code> (namelist.py)","text":"Parameter Type Default Unit Description <code>iera_type</code> integer type of ERA climatology: ERA5 (1) and ERA-I (2) <code>raw_data_era_path</code> character path to ERA raw data <code>raw_data_era_ORO</code> character filenames of ERA ORO raw data <code>raw_data_era_SD</code> character filenames of ERA SD raw data <code>raw_data_era_T2M</code> character filenames of ERA T2M raw data <code>raw_data_era_SST</code> character filenames of ERA SST raw data <code>era_buffer_file</code> character name for ERA parameter buffer file"},{"location":"user_manual/user_manual_06_namelist_input/#namelist_input_for_extpar_consistency_check","title":"Consistency Check","text":""},{"location":"user_manual/user_manual_06_namelist_input/#namelist-extpar_consistency_check_io-input_check","title":"NAMELIST <code>/extpar_consistency_check_io/</code> (INPUT_CHECK)","text":"Parameter Type Default Unit Description <code>l_use_array_cache</code> flag F flag indicating whether mmap-caching is used (reduces memory consumption but increases runtime) <code>netcdf_output_filename</code> character filename for NetCDF output <code>i_lsm_data</code> integer integer switch to choose if an external land-sea mask is desired (0: no, 1: use external land-sea mask) <code>land_sea_mask_file</code> character name of the file used as the external land-sea mask <code>number_special_points</code> integer number of points that should be treated specially (max value: 3, choose 0 if not needed) <code>lwrite_netcdf</code> logical T flag indicating whether NetCDF output for COSMO grid is desired <code>tile_mode</code> integer 0 if activated (<code>tile_mode=1</code>), process output for ICON tile structure <code>lflake_correction</code> logical T if activated, <code>fr_lake</code> values of grid points next to the ocean are set to ocean values, and the lake depth value is set to undefined (default in EXTPAR version 4.0, but not in DWD EXTPAR version 2.10)"},{"location":"user_manual/user_manual_06_namelist_input/#namelist-special_points-input_sp_1","title":"NAMELIST <code>/special_points/</code> (INPUT_SP_1)","text":"<p>Modifications for Falkenberg.</p> Parameter Type Default Unit Description <code>lon_geo_sp</code> real 14.115 deg east longitude coordinate of the special point <code>lat_geo_sp</code> real 52.156 deg north latitude coordinate of the special point <code>soiltype_sp</code> real 3.0 - soil type of the special point <code>z0_sp</code> real 0.03 m roughness length of the special point <code>rootdp_sp</code> real 0.6 m rooting depth of the special point <code>plcovmn_sp</code> real 0.55 1 plant cover minimum of the special point <code>plcovmx_sp</code> real 0.8 1 plant cover maximum of the special point <code>laimn_sp</code> real 0.5 1 leaf area index minimum of the special point <code>laimx_sp</code> real 2.5 1 leaf area index maximum of the special point <code>for_d_sp</code> real 1 ground fraction covered by deciduous forest at the special point <code>for_e_sp</code> real 1 ground fraction covered by evergreen forest at the special point <code>fr_land_sp</code> real 1 fraction land cover of the special point"},{"location":"user_manual/user_manual_06_namelist_input/#namelist-special_points-input_sp_2","title":"NAMELIST <code>/special_points/</code> (INPUT_SP_2)","text":"<p>Modifications for Waldstation.</p> Parameter Type Default Unit Description <code>lon_geo_sp</code> real 13.954 deg east longitude coordinate of the special point <code>lat_geo_sp</code> real 52.186 deg north latitude coordinate of the special point <code>soiltype_sp</code> real 3.0 - soil type of the special point <code>z0_sp</code> real 0.78 m roughness length of the special point <code>rootdp_sp</code> real 0.6 m rooting depth of the special point <code>plcovmn_sp</code> real 0.79 1 plant cover minimum of the special point <code>plcovmx_sp</code> real 0.81 1 plant cover maximum of the special point <code>laimn_sp</code> real 3.0 1 leaf area index minimum of the special point <code>laimx_sp</code> real 4.0 1 leaf area index maximum of the special point <code>for_d_sp</code> real 1 ground fraction covered by deciduous forest at the special point <code>for_e_sp</code> real 1 ground fraction covered by evergreen forest at the special point <code>fr_land_sp</code> real 1 fraction land cover of the special point"}]}